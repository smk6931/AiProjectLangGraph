import json
import asyncio
import time
import traceback

from datetime import date, datetime, timedelta
from sqlalchemy import func
from app.core.db import SessionLocal, fetch_all
from app.report.report_schema import StoreReport
from app.clients.genai import genai_generate_text
from app.order.order_service import select_daily_sales_by_store
from app.review.review_service import select_reviews_by_store
from app.core.cache import get_report_cache, set_report_cache, get_report_object_cache
from app.report.report_graph import report_graph_app


# ------------------------------------------------------------------
# [Portfolio] Redis vs DB Speed Race Helper Functions (Flattened)
# ------------------------------------------------------------------

async def _measure_redis_speed(s_id: int, check_date: date):
    """Redis ì¡°íšŒ ì†ë„ ì¸¡ì •"""
    start = time.perf_counter()
    data = await get_report_cache(s_id, check_date)
    dur = time.perf_counter() - start
    return dur, data


async def _measure_db_speed(s_id: int, check_date: date):
    """DB ì¡°íšŒ ì†ë„ ì¸¡ì •"""
    start = time.perf_counter()
    row = await select_latest_report(s_id)
    data = None
    if row and str(row['report_date']) == str(check_date):
        data = row
    dur = time.perf_counter() - start
    return dur, data


async def race_condition_check(s_id: int, t_date: str):
    """
    Redisì™€ DBì˜ ì¡°íšŒ ì†ë„ë¥¼ ê²½ìŸ(Race)ì‹œí‚¤ëŠ” ë©”ì¸ ë¡œì§.
    asyncio.gatherë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ íƒœìŠ¤í¬ë¥¼ ë™ì‹œì— ì‹¤í–‰í•¨.
    """
    logs = []
    
    if t_date:
        check_date = datetime.strptime(t_date, "%Y-%m-%d").date()
    else:
        check_date = date.today()

    # Async Execution (Race Start!) ğŸ”«
    # í—¬í¼ í•¨ìˆ˜ë“¤ì„ ë™ì‹œì— í˜¸ì¶œ
    (redis_time, redis_data), (db_time, db_data) = await asyncio.gather(
        _measure_redis_speed(s_id, check_date), 
        _measure_db_speed(s_id, check_date)
    )
    
    data_found = redis_data if redis_data else db_data
    
    # ë°ì´í„°ê°€ ì–´ë”˜ê°€ì— ìˆë‹¤ë©´ Race Log ìƒì„±
    if data_found:
        winner = "Redis" if redis_time < db_time else "DB"
        gap = db_time / redis_time if redis_time > 0 else 99.9
        
        logs.append(f"ğŸï¸ [Race] {winner} Win! (Redis: {redis_time:.4f}s vs DB: {db_time:.4f}s)")
        logs.append(f"âš¡ [ì†ë„ ë¹„êµ] Redisê°€ DBë³´ë‹¤ {gap:.1f}ë°° ë” ë¹ ë¦…ë‹ˆë‹¤!")
        
        # DB ë°ì´í„°ë§Œ ìˆëŠ” ê²½ìš° í¬ë§· ë§ì¶¤ (UI í˜¸í™˜ì„±)
        if not redis_data and db_data:
                # DB Rowë¥¼ Dict êµ¬ì¡°ë¡œ ê°ì‹¸ê¸°
                data_found = {"report": db_data, "logs": [], "mode": "sequential"}

    return data_found, logs


# ------------------------------------------------------------------
# Main Service Function
# ------------------------------------------------------------------

async def generate_ai_store_report(store_id: int, store_name: str, mode: str = "sequential", target_date: str = None):
    """
    LangGraph í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (Sequential Graph)
    ìºì‹œ í™•ì¸ â†’ ì—†ìœ¼ë©´ ìƒì„± â†’ ìºì‹œ ì €ì¥
    """
    try:
        print(f"ğŸš€ [Service] '{store_name}' ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ ({target_date if target_date else 'Today'})...")

        # 1. [Race] ìºì‹œ/DB ê²½ìŸ ì¡°íšŒ (Flattened êµ¬ì¡°)
        cached_data, race_logs = await race_condition_check(store_id, target_date)
        
        if cached_data:
            print(f"â™»ï¸ [Service] '{store_name}' ë¦¬í¬íŠ¸ ì¡°íšŒ ì„±ê³µ! (Race Winner Logic)")
            
            # ê¸°ì¡´ ë¡œê·¸ì— ë ˆì´ìŠ¤ ë¡œê·¸ ë³‘í•©
            final_logs = race_logs + cached_data.get("logs", [])
            cached_data["logs"] = final_logs
            cached_data["cached"] = True
            return cached_data

        # 2. ë¦¬í¬íŠ¸ ìƒì„± (ë°ì´í„° ì—†ìŒ -> AI ì‹¤í–‰)
        initial_state = {
            "store_id": store_id,
            "store_name": store_name,
            "target_date": target_date, # [NEW] ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ
            "execution_logs": race_logs # Race ê²°ê³¼(ì—†ìŒ)ë„ ë¡œê·¸ì— ë‚¨ê¹€
        }

        # LangGraph ì‹¤í–‰ (ë¯¸ë¦¬ ì»´íŒŒì¼ëœ ì‹±ê¸€í†¤ ì•± ì‚¬ìš©)
        final_state = await report_graph_app.ainvoke(initial_state)

        # DBì—ì„œ ì €ì¥ëœ ë¦¬í¬íŠ¸ ì¡°íšŒ
        report = await select_latest_report(store_id)

        # ì‹¤í–‰ ë¡œê·¸ ìˆ˜ì§‘
        logs = race_logs + final_state.get("execution_logs", [])

        result = {
            "report": report,
            "logs": logs,
            "mode": mode,
            "cached": False
        }

        # 3. ìƒì„±ëœ ë¦¬í¬íŠ¸ë¥¼ ìºì‹œì— ì €ì¥ (Redis + DBëŠ” ì´ë¯¸ ìœ„ì—ì„œ ë¨)
        # target_dateê°€ ìˆìœ¼ë©´ ê·¸ê±¸ë¡œ, ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œë¡œ key ìƒì„±
        save_date = datetime.strptime(target_date, "%Y-%m-%d").date() if target_date else date.today()
        
        # [Prevent Caching Bad Data] ë¶ˆëŸ‰ ë¦¬í¬íŠ¸(Risk Score=0)ëŠ” Redis ì €ì¥ ê±´ë„ˆë›°ê¸°
        risk_check = report.get("risk_assessment") if report else None
        risk_score = risk_check.get("risk_score") if risk_check else 0
        
        if risk_score and risk_score > 0:
            await set_report_cache(store_id, result, save_date)
        else:
            print("âš ï¸ [Cache Skip] ë¶ˆëŸ‰ ë¦¬í¬íŠ¸ë¼ Redis ìºì‹±ì„ ìƒëµí•©ë‹ˆë‹¤.")

        return result

    except Exception as e:
        print(f"âŒ [Service] ì—ëŸ¬ ë°œìƒ: {str(e)}")
        traceback.print_exc()
        return None


async def select_latest_report(store_id: int):
    """
    ì§€ì ì˜ ê°€ì¥ ìµœì‹  ë¦¬í¬íŠ¸ ì¡°íšŒ (DB Only)
    """
    sql = "SELECT * FROM store_reports WHERE store_id = %s ORDER BY report_date DESC, report_id DESC LIMIT 1"
    rows = await fetch_all(sql, (store_id,))
    return rows[0] if rows else None
