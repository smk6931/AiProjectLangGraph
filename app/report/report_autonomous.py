import os
import json
from typing import Annotated, TypedDict, List, Dict, Any, Union
from datetime import date

# LangChain & LangGraph ê´€ë ¨ ì„í¬íŠ¸
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.graph.message import add_messages

# ê¸°ì¡´ í”„ë¡œì íŠ¸ ì„œë¹„ìŠ¤ ë° ëª¨ë¸ ì„í¬íŠ¸
from app.core.db import SessionLocal
from app.report.report_schema import StoreReport
from app.order.order_service import select_daily_sales_by_store
from app.review.review_service import select_reviews_by_store

# 1. ì—ì´ì „íŠ¸ ìƒíƒœ(State) ì •ì˜
class AgentState(TypedDict):
    # add_messages ë¦¬ë“€ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ê°€ ìë™ìœ¼ë¡œ ëˆ„ì ë˜ë„ë¡ í•©ë‹ˆë‹¤.
    messages: Annotated[List[BaseMessage], add_messages]
    store_id: int
    store_name: str

# 2. ììœ¨ì ìœ¼ë¡œ ì‹¤í–‰ë  íˆ´(Tool) ì •ì˜

@tool
async def fetch_store_data(store_id: int):
    """ì§€ì ì˜ ìµœê·¼ ë§¤ì¶œê³¼ ë¦¬ë·° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ë¶„ì„ì„ ìœ„í•´ ì²˜ìŒ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤."""
    print(f"ğŸ› ï¸ [Tool] ë°ì´í„° ìˆ˜ì§‘ ì¤‘ (ID: {store_id})")
    sales = await select_daily_sales_by_store(store_id)
    reviews = await select_reviews_by_store(store_id)
    
    data_summary = {
        "sales": [{"date": str(s['order_date']), "revenue": float(s['daily_revenue'])} for s in sales[:7]],
        "reviews": [{"rating": r['rating'], "comment": r['review_text']} for r in reviews[:15]]
    }
    return json.dumps(data_summary, ensure_ascii=False)

@tool
async def save_strategic_report(
    store_id: int, 
    summary: str, 
    marketing_strategy: str, 
    operational_improvement: str, 
    risk_score: int
):
    """ë¶„ì„ì´ ì™„ë£Œëœ ì „ëµ ë¦¬í¬íŠ¸ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤. ë¶„ì„ì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ì— í˜¸ì¶œí•˜ì„¸ìš”."""
    print(f"ğŸ› ï¸ [Tool] ë¦¬í¬íŠ¸ ì €ì¥ ì¤‘ (ID: {store_id})")
    
    db_report = StoreReport(
        store_id=store_id,
        report_date=date.today(),
        report_type="AI_AUTONOMOUS_REPORT",
        summary=summary,
        marketing_strategy=marketing_strategy,
        operational_improvement=operational_improvement,
        risk_assessment={"risk_score": risk_score, "generated_at": str(date.today())}
    )
    
    try:
        with SessionLocal() as session:
            session.query(StoreReport).filter_by(store_id=store_id, report_date=date.today()).delete()
            session.add(db_report)
            session.commit()
        return "ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        print(f"âŒ [Tool] ì €ì¥ ì¤‘ ì—ëŸ¬: {e}")
        return f"ì €ì¥ ì‹¤íŒ¨: {str(e)}"

# 3. ë…¸ë“œ(Node) ì •ì˜

async def call_model(state: AgentState):
    """LLMì´ í˜„ì¬ ìƒíƒœë¥¼ ë³´ê³  ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•˜ëŠ” ë…¸ë“œ"""
    print("\n" + "â•"*60)
    print(f"ğŸ¤– [Agent: Reasoning] '{state['store_name']}' ì§€ì  ë¶„ì„ ì¤‘...")
    
    messages = state.get("messages", [])
    
    # 1. AIê°€ ì½ì„ ì´ì „ ë©”ì‹œì§€ ìš”ì•½ ë¡œê·¸
    if messages:
        last_msg = messages[-1]
        print(f"ï¿½ [Input Context]: ë§ˆì§€ë§‰ ë©”ì‹œì§€ íƒ€ì… -> {type(last_msg).__name__}")
        if hasattr(last_msg, 'content') and last_msg.content:
            # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì¶œë ¥
            preview = last_msg.content[:100] + "..." if len(last_msg.content) > 100 else last_msg.content
            print(f"   ë‚´ìš© ìš”ì•½: {preview}")

    # 2. ì´ˆê¸° ë©”ì‹œì§€ ì„¤ì •
    new_messages = []
    if not messages:
        print("ğŸš© [System] ë¶„ì„ í”„ë¡œì„¸ìŠ¤ë¥¼ ì²˜ìŒ ì‹œì‘í•©ë‹ˆë‹¤. ì´ˆê¸° ì§€ì¹¨ ìƒì„± ì¤‘...")
        sys_msg = SystemMessage(content=f"ë‹¹ì‹ ì€ '{state['store_name']}' ì§€ì ì˜ ê²½ì˜ ì „ëµê°€ì…ë‹ˆë‹¤. fetch_store_dataë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•œ ë’¤, ë°˜ë“œì‹œ save_strategic_reportë¡œ ë¦¬í¬íŠ¸ë¥¼ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤. íŒë‹¨ ê·¼ê±°ë¥¼ í•œêµ­ì–´ë¡œ ëª…í™•íˆ ë°í˜€ì£¼ì„¸ìš”.")
        prompt = HumanMessage(content="ë¶„ì„ì„ ì‹œì‘í•˜ê³  ë¦¬í¬íŠ¸ë¥¼ ì €ì¥í•´ì£¼ì„¸ìš”.")
        messages = [sys_msg, prompt]
        new_messages.extend(messages)

    # LLM ì„¤ì •
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash", 
        google_api_key=os.getenv("GEMINI_API_KEY"),
        temperature=0
    )
    llm_with_tools = llm.bind_tools([fetch_store_data, save_strategic_report])
    
    # AIì—ê²Œ ìƒê° ì „ê°œ ìš”ì²­
    response = await llm_with_tools.ainvoke(messages)
    
    # 3. AIì˜ ìƒê°(Thought) ì¶œë ¥
    if response.content:
        print(f"\nğŸ’¡ [AI Thought]:\n{response.content}")
    
    # 4. AIê°€ ê²°ì •í•œ íˆ´ í˜¸ì¶œ ë° ë§¤ê°œë³€ìˆ˜ ë§¤í•‘ ë¡œê·¸
    if response.tool_calls:
        print(f"\nğŸ¯ [Tool Call Decision]:")
        for tool_call in response.tool_calls:
            print(f"   í•¨ìˆ˜ëª…: {tool_call['name']}")
            print(f"   ë§¤í•‘ëœ ì¸ì(Args): {json.dumps(tool_call['args'], indent=5, ensure_ascii=False)}")
    
    new_messages.append(response)
    print("â•"*60)
    
    return {"messages": new_messages}

# 4. ê·¸ë˜í”„(Graph) ë¹Œë“œ

def create_autonomous_report_graph():
    workflow = StateGraph(AgentState)
    workflow.add_node("agent", call_model)
    workflow.add_node("tools", ToolNode([fetch_store_data, save_strategic_report]))
    
    workflow.set_entry_point("agent")

    def should_continue(state: AgentState):
        last_message = state["messages"][-1]
        # íˆ´ í˜¸ì¶œì´ ìˆìœ¼ë©´ tools ë…¸ë“œë¡œ, ì—†ìœ¼ë©´ ì¢…ë£Œ
        if hasattr(last_message, "tool_calls") and last_message.tool_calls:
            return "tools"
        return END

    workflow.add_conditional_edges("agent", should_continue)
    workflow.add_edge("tools", "agent")
    
    return workflow.compile()

# ì‹¤í–‰ìš© ì „ì—­ ê°ì²´
autonomous_report_app = create_autonomous_report_graph()
