import os
import json
from typing import Annotated, TypedDict, List
from datetime import date

# LangChain & LangGraph ê´€ë ¨ ì„í¬íŠ¸
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.graph.message import add_messages

# ê¸°ì¡´ í”„ë¡œì íŠ¸ ì„œë¹„ìŠ¤ ë° ëª¨ë¸ ì„í¬íŠ¸
from app.core.db import SessionLocal
from app.report.report_schema import StoreReport
from app.order.order_service import select_daily_sales_by_store, select_menu_sales_comparison, select_sales_by_day_type
from app.review.review_service import select_reviews_by_store
from app.clients.weather import fetch_weather_data

# 1. ìƒíƒœ(State) ì •ì˜: "ì—ì´ì „íŠ¸ê°€ ë“¤ê³  ë‹¤ë‹ ê³µìœ  ë©”ëª¨ì¥"


class AgentState(TypedDict):
    # add_messages: ìƒˆë¡œìš´ ë©”ì‹œì§€ê°€ ìƒê¸°ë©´ ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ì— ìë™ìœ¼ë¡œ í•©ì³ì¤ë‹ˆë‹¤.
    messages: Annotated[List[BaseMessage], add_messages]
    store_id: int
    store_name: str

# 2. ë„êµ¬(Tools) ì •ì˜: "ì—ì´ì „íŠ¸ê°€ ì†ë°œì²˜ëŸ¼ ì‚¬ìš©í•  ê¸°ëŠ¥ë“¤"

@tool
async def fetch_store_data(store_id: int):
    """ì§€ì ì˜ ìµœê·¼ ë§¤ì¶œê³¼ ë¦¬ë·° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì£¼ìš” ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    print(f"ğŸ› ï¸ [Tool] {store_id}ë²ˆ ì§€ì  ë°ì´í„° ë¶„ì„ ì¤‘...")
    sales = await select_daily_sales_by_store(store_id)
    reviews = await select_reviews_by_store(store_id)
    menu_stats = await select_menu_sales_comparison(store_id, days=7)
    day_stats = await select_sales_by_day_type(store_id, days=7)

    # ê¸°ë³¸ ìˆ˜ì¹˜ ê³„ì‚°
    total_rev = sum(float(s['daily_revenue']) for s in sales)
    avg_rating = sum(r['rating'] for r in reviews) / len(reviews) if reviews else 0
    
    # ìµœê·¼ 3ì¼ vs ì´ì „ 4ì¼ ë¹„êµ (ì—¬ì „íˆ ìœ ì§€í•˜ì§€ë§Œ, ë©”ë‰´ ë¶„ì„ì€ 7ì¼ ê¸°ì¤€)
    recent_3 = sum(float(s['daily_revenue']) for s in sales[:3]) / 3 if len(sales) >= 3 else 0
    prev_4 = sum(float(s['daily_revenue']) for s in sales[3:7]) / 4 if len(sales) >= 7 else total_rev/7
    trend = ((recent_3 - prev_4) / prev_4 * 100) if prev_4 > 0 else 0

    # ë©”ë‰´ë³„ ì¦ê° ë¶„ì„ (ë§¤ì¶œ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ëœ ìƒíƒœ)
    # 1. Top Selling (ë§¤ì¶œì•¡ ìƒìœ„)
    top_selling = []
    # 2. Top Dropping (ê°ì†Œí­ í•˜ìœ„ - ì—­ì„±ì¥)
    # ê³„ì‚°ì„ ìœ„í•´ ëª¨ë“  ë¦¬ìŠ¤íŠ¸ ë³€í™˜
    processed_menus = []
    for m in menu_stats:
        rec_rev = float(m['recent_revenue'])
        prev_rev = float(m['prev_revenue'])
        change_pct = ((rec_rev - prev_rev) / prev_rev * 100) if prev_rev > 0 else (100 if rec_rev > 0 else 0)
        
        item = {
            "menu": m['menu_name'],
            "cat": m['category'],
            "recent_rev": rec_rev,
            "prev_rev": prev_rev,
            "change_pct": round(change_pct, 1)
        }
        processed_menus.append(item)
    
    # ë§¤ì¶œì•¡ ê¸°ì¤€ ì •ë ¬
    sorted_by_rev = sorted(processed_menus, key=lambda x: x['recent_rev'], reverse=True)
    top_selling = sorted_by_rev[:5]

    # ê°ì†Œìœ¨ ê¸°ì¤€ ì •ë ¬ (í•˜ë½í­ì´ í° ìˆœì„œ -> change_pctê°€ ì‘ì€ ìˆœì„œ)
    # ë‹¨, ì´ì „ ë§¤ì¶œì´ ìˆì—ˆë˜ í•­ëª© ì¤‘ì—ì„œë§Œ ë”°ì§€ëŠ”ê²Œ ì˜ë¯¸ê°€ ìˆìŒ (prev_rev > 0)
    dropping_candidates = [m for m in processed_menus if m['prev_rev'] > 0]
    sorted_by_drop = sorted(dropping_candidates, key=lambda x: x['change_pct']) # ì˜¤ë¦„ì°¨ìˆœ (ì˜ˆ: -50%, -10%, +5%)
    worst_dropping = sorted_by_drop[:5]

    # ìš”ì¼ë³„(í‰ì¼/ì£¼ë§) ë¶„ì„
    day_analysis = []
    for d in day_stats:
        r_rev = float(d['recent_revenue'])
        p_rev = float(d['prev_revenue'])
        d_trend = ((r_rev - p_rev) / p_rev * 100) if p_rev > 0 else 0
        day_analysis.append({
            "type": d['day_type'],
            "recent": r_rev,
            "prev": p_rev,
            "trend": round(d_trend, 1)
        })

    # ë§¤ì¶œ ë¦¬ìŠ¤íŠ¸ì— ë‚ ì”¨ ì •ë³´ (DBì—ì„œ ì´ë¯¸ ê°€ì ¸ì˜´)
    recent_sales_with_weather = []
    # salesëŠ” ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ(ASC)ì´ë¯€ë¡œ, ìµœê·¼ 7ì¼ ë°ì´í„°ëŠ” ë¦¬ìŠ¤íŠ¸ì˜ ë’¤ìª½ ë°ì´í„°ì…ë‹ˆë‹¤.
    # sales[-7:] = [D-6, D-5, ... D-day]
    # recent_3 (ìµœê·¼ 3ì¼): sales[-3:]
    # prev_4 (ê·¸ì „ 4ì¼): sales[-7:-3]
    
    # I will fix this logic to be correct for ASC sorted data.
    
    target_sales = sales[-7:] if len(sales) >= 7 else sales
    
    recent_sales_with_weather = []
    # ì°¨íŠ¸ í‘œì‹œë¥¼ ìœ„í•´ ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ ìœ ì§€
    
    for s in target_sales:
        d_str = str(s['order_date'])
        recent_sales_with_weather.append({
            "date": d_str,
            "rev": float(s['daily_revenue']),
            "weather": s.get('weather_info', "ì•Œìˆ˜ì—†ìŒ")
        })
        
    # ì „ì²´ ê¸°ê°„ì— ëŒ€í•œ í†µê³„ ê³„ì‚°
    
    total_rev = sum(float(s['daily_revenue']) for s in target_sales) # Let's focus on recent 7 days for the report metrics to be consistent with text "Recent 7 days"
    avg_rev = total_rev / len(target_sales) if target_sales else 0
    
    # Trend: Recent 3 vs Prev 4 within the 7 days window
    if len(target_sales) >= 7:
        # sales are ASC: [0,1,2,3, 4,5,6]
        # recent 3: 4,5,6 -> sales[4:]
        # prev 4: 0,1,2,3 -> sales[:4]
        rec_slice = target_sales[4:]
        prev_slice = target_sales[:4]
        
        recent_3_sum = sum(float(s['daily_revenue']) for s in rec_slice)
        recent_3_avg = recent_3_sum / 3
        
        prev_4_sum = sum(float(s['daily_revenue']) for s in prev_slice)
        prev_4_avg = prev_4_sum / 4
        
        trend = ((recent_3_avg - prev_4_avg) / prev_4_avg * 100) if prev_4_avg > 0 else 0
    else:
         trend = 0

    data_summary = {
        "metrics": {
            "total_rev": total_rev,
            "avg_rev": avg_rev,
            "trend_percent": trend,
            "avg_rating": avg_rating
        },
        "recent_sales": recent_sales_with_weather,
        "top_reviews": [{"rate": r['rating'], "text": r['review_text']} for r in reviews[:10]],
        "top_selling_menus": top_selling,
        "worst_dropping_menus": worst_dropping,
        "day_analysis": day_analysis
    }
    return json.dumps(data_summary, ensure_ascii=False)


@tool
async def save_strategic_report(
    store_id: int,
    summary: str,
    marketing_strategy: str,
    operational_improvement: str,
    data_evidence_json: str,
    metrics_json: str,
    source_data_json: str = None,
    risk_score: int = 50
):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤.
    - data_evidence_json: ë¶„ì„ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ìˆ˜ì¹˜ ë° ë¬¸êµ¬ (JSON)
    - metrics_json: ê³„ì‚°ëœ í•µì‹¬ ì§€í‘œ (JSON)
    - source_data_json: ë¶„ì„ì— ì‚¬ìš©ëœ ê¸°ì´ˆ ë°ì´í„° (ìµœê·¼ ë§¤ì¶œ ë“±)
    """
    print(f"ğŸ› ï¸ [Tool] ë¦¬í¬íŠ¸ ì €ì¥ ì¤‘ (ID: {store_id})")

    risk_info = {
        "risk_score": risk_score,
        "metrics": json.loads(metrics_json) if isinstance(metrics_json, str) else metrics_json,
        "data_evidence": json.loads(data_evidence_json) if isinstance(data_evidence_json, str) else data_evidence_json
    }
    
    if source_data_json:
        risk_info["source_data"] = json.loads(source_data_json) if isinstance(source_data_json, str) else source_data_json

    db_report = StoreReport(
        store_id=store_id,
        report_date=date.today(),
        report_type="AI_AUTONOMOUS_REPORT",
        summary=summary,
        marketing_strategy=marketing_strategy,
        operational_improvement=operational_improvement,
        risk_assessment=risk_info
    )

    with SessionLocal() as session:
        session.query(StoreReport).filter_by(
            store_id=store_id, report_date=date.today()).delete()
        session.add(db_report)
        session.commit()

    return "ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì—…ë¬´ë¥¼ ì¢…ë£Œí•˜ì„¸ìš”."

# 3. ë…¸ë“œ(Node) ì •ì˜: "ì‹¤ì œë¡œ ì¼í•˜ëŠ” ì‘ì—…ì"


async def call_model(state: AgentState):
    """AIê°€ í˜„ì¬ ìƒí™©ì„ ë³´ê³  íŒë‹¨í•˜ì—¬ í–‰ë™(ë§í•˜ê¸° ë˜ëŠ” íˆ´ ì‚¬ìš©)ì„ ê²°ì •í•˜ëŠ” ë…¸ë“œ"""
    print("ğŸ¤– [Agent] ìƒê° ì¤‘...")

    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        google_api_key=os.getenv("GEMINI_API_KEY"),
        temperature=0
    )
    # AIì—ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë„êµ¬ë“¤ì„ ì—°ê²°í•´ì¤ë‹ˆë‹¤.
    llm_with_tools = llm.bind_tools([fetch_store_data, save_strategic_report])

    # ì²˜ìŒ ì‹œì‘í•  ë•Œ ì‹œìŠ¤í…œ ì§€ì¹¨(SystemMessage)ì„ ë„£ì–´ì¤ë‹ˆë‹¤.
    messages = state.get("messages", [])
    if not messages:
        sys_msg = SystemMessage(content=(
            f"ë‹¹ì‹ ì€ '{state['store_name']}' ì§€ì ì˜ ê²½ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n"
            "1. fetch_store_dataë¡œ ë§¤ì¶œ, ë‚ ì”¨, ë©”ë‰´, ìš”ì¼ë³„ ë°ì´í„°ë¥¼ ëª¨ë‘ ìˆ˜ì§‘í•˜ì„¸ìš”.\n"
            "2. **'ì™¸ë¶€ ìš”ì¸(ë‚ ì”¨) ë¶„ì„'**ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n"
            "   - 'ë¹„ì˜¤ëŠ” ë‚  ë§¤ì¶œ í•˜ë½'ì€ ì •ìƒ ì°¸ì‘(Normal)ì´ì§€ë§Œ, **'ë§‘ì€ ë‚ ì¸ë°ë„ í‰ì†Œë³´ë‹¤ ë§¤ì¶œì´ ê¸‰ê°'**í–ˆë‹¤ë©´ ì´ë¥¼ 'ì‹¬ê°í•œ ìœ„ê¸°(Critical Crisis)'ë¡œ ì§„ë‹¨í•˜ì„¸ìš”.\n"
            "   - ì˜ˆ: '12ì›” 20ì¼ì€ ë§‘ì•˜ìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ì§€ë‚œì£¼ ë™ìš”ì¼ ëŒ€ë¹„ ë§¤ì¶œì´ 30% í•˜ë½í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‚´ë¶€ ìš´ì˜ ë¬¸ì œì…ë‹ˆë‹¤.'\n"
            "3. ê¸°ì¡´ì˜ ë©”ë‰´/ìš”ì¼ ë¶„ì„(ë¬´ì—‡ì´/ì–¸ì œ ì•ˆ íŒ”ë ¸ë‚˜)ë„ ê³„ì† ì§„í–‰í•˜ì„¸ìš”.\n"
            "4. ë¦¬í¬íŠ¸ ì‘ì„± ì‹œ ìˆ˜ì¹˜ì  ê·¼ê±°(ë‚ ì”¨ í¬í•¨)ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ê³  ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ í™œìš©í•˜ì„¸ìš”."
        ))
        start_msg = HumanMessage(content="ì—…ë¬´ë¥¼ ì‹œì‘í•´ ì£¼ì„¸ìš”.")
        messages = [sys_msg, start_msg]

    response = await llm_with_tools.ainvoke(messages)

    # ê²°ê³¼ë¥¼ ë©”ëª¨ì¥(State)ì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    return {"messages": [response]}

# 4. ê·¸ë˜í”„(Graph) êµ¬ì„±: "ì¼ì˜ ìˆœì„œë„ ê·¸ë¦¬ê¸°"


def create_simple_autonomous_graph():
    # ë©”ëª¨ì¥(State)ì„ ì‚¬ìš©í•˜ëŠ” ì›Œí¬í”Œë¡œìš° ìƒì„±
    workflow = StateGraph(AgentState)

    # ì‘ì—…ì(Node) ë“±ë¡
    workflow.add_node("agent", call_model)
    workflow.add_node("tools", ToolNode(
        [fetch_store_data, save_strategic_report]))

    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("agent")

    workflow.add_conditional_edges( "agent",
        lambda stategraph: "tools" if stategraph["messages"][-1].tool_calls else "end",
        {
            "tools": "tools",
            "end": END
        }
    )

    workflow.add_edge("tools", "agent")

    return workflow.compile()

        # def should_continue(state: AgentState):
    #     last_message = state["messages"][-1]
    #     if last_message.tool_calls:
    #         return "tools"  
    #     return "end"       
