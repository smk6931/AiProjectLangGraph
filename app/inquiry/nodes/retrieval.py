import json
from typing import Dict, Any, List

# External App Imports
from app.clients.genai import genai_generate_with_grounding
from app.core.db import fetch_all
from app.inquiry.inquiry_schema import InquiryState

# ===== Step 4: Manual RAG Node (ë§¤ë‰´ì–¼ ê²€ìƒ‰) =====
async def manual_node(state: InquiryState) -> InquiryState:
    """ë§¤ë‰´ì–¼ DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (Vector Search)"""
    if state["category"] != "manual":
        return state
    
    question = state["question"]
    
    # OpenAI Embeddingsë¡œ ì§ˆë¬¸ ë²¡í„°í™”
    from langchain_openai import OpenAIEmbeddings
    embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")
    question_vector = embeddings_model.embed_query(question)
    
    # pgvector ìœ ì‚¬ë„ ê²€ìƒ‰ (ì½”ì‚¬ì¸ ê±°ë¦¬ ê¸°ì¤€ Top 3)
    # distanceê°€ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬í•¨
    query = f"""
    SELECT title, content, category,
           embedding <=> '{question_vector}'::vector AS distance
    FROM manuals
    ORDER BY distance
    LIMIT 5
    """
    
    rows = await fetch_all(query)
    
    # ê²€ìƒ‰ ê²°ê³¼ ë° ìµœì†Œ ê±°ë¦¬ ì €ì¥
    min_distance = 1.0 # ê¸°ë³¸ê°’ (ë¶ˆì¼ì¹˜)
    if rows:
        min_distance = min([r['distance'] for r in rows])
        
    state["manual_data"] = [
        f"[{row['title']}] (ìœ ì‚¬ë„: {1 - row['distance']:.2f})\n{row['content']}"
        for row in rows
    ]
    
    if "search_meta" not in state: state["search_meta"] = {}
    state["search_meta"] = {"min_distance": min_distance, "source": "manual_db"}
    
    print(f"ğŸ“– [Manual] ê²€ìƒ‰ ì™„ë£Œ (Min Distance: {min_distance:.4f})")
    return state


# ===== Step 5: Policy RAG Node (ì •ì±… ê²€ìƒ‰) =====
async def policy_node(state: InquiryState) -> InquiryState:
    """ìš´ì˜ ì •ì±… ë§¤ë‰´ì–¼ ê²€ìƒ‰ (Policies í…Œì´ë¸” ì¡°íšŒ)"""
    if state["category"] != "policy":
        return state
    
    question = state["question"]
    
    from langchain_openai import OpenAIEmbeddings
    embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")
    question_vector = embeddings_model.embed_query(question)
    
    query = f"""
    SELECT title, content, category,
           embedding <=> '{question_vector}'::vector AS distance
    FROM policies
    ORDER BY distance
    LIMIT 5
    """
    
    rows = await fetch_all(query)
    
    min_distance = 1.0
    if rows:
        min_distance = min([r['distance'] for r in rows])
        
    state["policy_data"] = [
        f"[{row['title']}] (ìœ ì‚¬ë„: {1 - row['distance']:.2f})\n{row['content']}"
        for row in rows
    ]
    
    state["search_meta"] = {"min_distance": min_distance, "source": "policy_db"}
    
    print(f"ğŸ“œ [Policy] ê²€ìƒ‰ ì™„ë£Œ (Min Distance: {min_distance:.4f})")
    return state


# ===== Step 5.5: Web Search Node (ì™¸ë¶€ ê²€ìƒ‰ - Google Grounding) =====
async def web_search_node(state: InquiryState) -> InquiryState:
    """ë‚´ë¶€ DB ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì™¸ë¶€ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ (Google Gemini Grounding)"""
    question = state["question"]
    print(f"ğŸŒ [Google Grounding] ë‚´ë¶€ ë¬¸ì„œ ë¶€ì¡± -> êµ¬ê¸€ ê²€ìƒ‰ ìˆ˜í–‰: {question}")
    
    try:
        # êµ¬ê¸€ ê²€ìƒ‰ Groundingì„ í†µí•œ ë‹µë³€ ìƒì„±
        grounded_response = await genai_generate_with_grounding(question)
        
        # ê²°ê³¼ ì €ì¥
        state["manual_data"] = [f"[Google ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ë‹µë³€]\n{grounded_response}"]
        state["search_meta"] = {"source": "web_search", "min_distance": 0.0}
        
    except Exception as e:
        print(f"âŒ Google Grounding ì‹¤íŒ¨: {e}")
        state["manual_data"] = [f"ì™¸ë¶€ ê²€ìƒ‰ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (Error: {str(e)})"]
        
    return state
