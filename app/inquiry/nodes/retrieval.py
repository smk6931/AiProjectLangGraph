import json
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from app.clients.genai import genai_generate_with_grounding # Gemini Grounding
from app.core.config import settings
from app.inquiry.state import InquiryState

# ë²¡í„° DB ì„¤ì • (ì„ì‹œ ê²½ë¡œ, ì‹¤ì œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
persist_directory = "./chroma_db" 
embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=settings.OPENAI_API_KEY)

async def retrieval_node(state: InquiryState) -> InquiryState:
    """
    [Retrieval Node]
    Manual/Policy ì§ˆë¬¸ì— ëŒ€í•´ Vector DB ê²€ìƒ‰ ë° Web Search Fallbackì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    question = state["question"]
    category = state["category"] # manual or policy
    
    print(f"ğŸ“˜ [Retrieval] Searching for category: {category}")
    
    search_results = []
    is_relevant = True
    recommendation = {"indices": [], "comment": ""}

    try:
        # 1. RAG Vector Search
        # (ì‹¤ì œ êµ¬í˜„ ì‹œì—” collection_nameì„ categoryì— ë”°ë¼ ë¶„ê¸°)
        collection_name = "manual_collection" if category == "manual" else "policy_collection"
        
        # Chroma DBê°€ ì—†ê±°ë‚˜ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì²˜ë¦¬ í•„ìš”
        try:
            vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name=collection_name)
            docs = vectorstore.similarity_search_with_score(question, k=3)
            
            # ê²€ìƒ‰ ê²°ê³¼ ê°€ê³µ
            for doc, score in docs:
                # scoreê°€ ë‚®ìœ¼ë©´(ê±°ë¦¬ê°€ ë©€ë©´) ê´€ë ¨ì„± ë‚®ìŒìœ¼ë¡œ íŒë‹¨ (ì˜ˆ: score > 0.5)
                # ChromaëŠ” L2 distanceë¥¼ ì“¸ ê²½ìš° 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬í•¨
                search_results.append(f"[Score: {score:.4f}] {doc.page_content}")
                
            # ê°€ì¥ ê°€ê¹Œìš´ ë¬¸ì„œì˜ ê±°ë¦¬ê°€ ë„ˆë¬´ ë©€ë©´ Web Search ì¶”ì²œ
            if docs and docs[0][1] > 0.6: # Threshold
                is_relevant = False
                recommendation["comment"] = "âš ï¸ ë‚´ë¶€ ë¬¸ì„œì™€ ìœ ì‚¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ì„ ì¶”ì²œí•©ë‹ˆë‹¤."
                
        except Exception as e:
            print(f"âš ï¸ [VecDB Error] {e}")
            is_relevant = False # DB ì—ëŸ¬ ì‹œ ì›¹ ê²€ìƒ‰ ìœ ë„

        # 2. Web Search (Fallback or Recommendation)
        # ë§Œì•½ ê´€ë ¨ì„±ì´ ë‚®ë‹¤ê³  íŒë‹¨ë˜ë©´ Gemini Grounding ì‹¤í–‰ (Optional)
        # ì—¬ê¸°ì„œëŠ” ì¶”ì²œ ë©”ì‹œì§€ë§Œ ë‚¨ê¸°ê³ , ì‹¤ì œ ì‹¤í–‰ì€ Answer ë‹¨ê³„ë‚˜ UI ì„ íƒì— ë§¡ê¸¸ ìˆ˜ë„ ìˆìŒ.
        # í•˜ì§€ë§Œ Auto-Feedback ë£¨í”„ë¼ë©´ ì—¬ê¸°ì„œ ë°”ë¡œ Web Searchë¥¼ ëŒë¦´ ìˆ˜ë„ ìˆìŒ.
        
        if not is_relevant:
            print("ğŸŒ [Web Search] Triggering Gemini Grounding...")
            web_res = await genai_generate_with_grounding(question)
            search_results.append(f"====== [Web Search Result] ======\n{web_res}")

    except Exception as e:
        print(f"âŒ [Retrieval Error] {e}")

    return {
        "search_results": search_results,
        "is_relevant": is_relevant,
        "recommendation": recommendation
    }
