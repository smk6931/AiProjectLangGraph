import json
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from app.core.config import settings
from app.inquiry.state import InquiryState

llm = ChatOpenAI(model="gpt-4o", temperature=0, openai_api_key=settings.OPENAI_API_KEY)

async def answer_node(state: InquiryState) -> InquiryState:
    """
    [Answer Node]
    ìˆ˜ì§‘ëœ ëª¨ë“  ì •ë³´(SQL ê²°ê³¼, RAG ë¬¸ì„œ, ì›¹ ê²€ìƒ‰ ë“±)ë¥¼ ì¢…í•©í•˜ì—¬ 
    ìµœì¢… ë‹µë³€ì„ JSON í˜•íƒœë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    """
    question = state["question"]
    category = state.get("category", "general")
    sales_data = state.get("sales_data", {})
    search_results = state.get("search_results", [])
    
    print(f"ğŸ’¬ [Answer] Generating response for {category}")

    # ì»¨í…ìŠ¤íŠ¸ ì¡°ë¦½
    context_text = ""
    if category == "sales":
        context_text = f"SQL Result: {sales_data.get('sql_result', 'No Data')}\n"
        context_text += f"Reviews: {sales_data.get('recent_reviews', 'No Reviews')}"
    else:
        context_text = "\n".join(search_results)
        
    # í”„ë¡¬í”„íŠ¸
    answer_prompt = ChatPromptTemplate.from_template("""
        SYSTEM: ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ í”„ëœì°¨ì´ì¦ˆ ë§¤ë‹ˆì € AIì…ë‹ˆë‹¤.
        ì œê³µëœ [Context]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ [Question]ì— ë‹µë³€í•˜ì„¸ìš”.
        
        [Context]
        {context}
        
        [Output Requirements]
        - ë°˜ë“œì‹œ ì•„ë˜ JSON í¬ë§·ì„ ì¤€ìˆ˜í•˜ì„¸ìš”.
        - `answer`: ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ í…ìŠ¤íŠ¸ (Markdown ì§€ì›).
        - `chart_data`: (ë§¤ì¶œ ì§ˆë¬¸ì¸ ê²½ìš°) ì°¨íŠ¸ì— ì‚¬ìš©í•  ë°ì´í„° ë¦¬ìŠ¤íŠ¸. ì—†ìœ¼ë©´ [].
        - `key_metrics`: (ë§¤ì¶œ ì§ˆë¬¸ì¸ ê²½ìš°) ê°•ì¡°í•  ìˆ«ì ì§€í‘œ.
        
        [JSON Format]
        {{
            "answer": "ì•ˆë…•í•˜ì„¸ìš” ì ì£¼ë‹˜, ìš”ì²­í•˜ì‹ ...",
            "chart_data": [ {{ "label": "...", "value": 100 }} ],
            "key_metrics": [ {{ "label": "ì´ ë§¤ì¶œ", "value": "1,000,000ì›", "delta": "+5%" }} ],
            "used_docs": [] // ì°¸ê³ í•œ ë¬¸ì„œ ì¸ë±ìŠ¤ (RAGì¸ ê²½ìš°)
        }}
        
        USER: {question}
    """)
    
    chain = answer_prompt | llm
    res = await chain.ainvoke({"context": context_text, "question": question})
    
    try:
        clean_json = res.content.replace("```json", "").replace("```", "").strip()
        final_answer = json.loads(clean_json)
    except:
        final_answer = {
            "answer": res.content,
            "chart_data": [],
            "key_metrics": []
        }
        
    return {"final_answer": final_answer}
