import json
from datetime import datetime, timedelta
from typing import Dict, Any, List

# External App Imports
from app.clients.genai import genai_generate_text
from app.core.db import fetch_all
from app.inquiry.inquiry_schema import InquiryState

# ===== Search Param Extraction Helper =====
async def extract_search_params(question: str):
    """
    ì§ˆë¬¸ ë¶„ì„ -> ë¶„ì„ ëŒ€ìƒ(ë§¤ì¥ë“¤) & í•„ìš”í•œ ë°ì´í„° ì†ŒìŠ¤(í…Œì´ë¸”) ê²°ì •
    """
    prompt = f"""
    ë‹¹ì‹ ì€ ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ 'ìˆëŠ” ê·¸ëŒ€ë¡œ ì¶”ì¶œ'í•˜ëŠ” AIì…ë‹ˆë‹¤. (ë²ˆì—­/í•´ì„ ê¸ˆì§€)
    ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë¶„ì„ ëŒ€ìƒ ë§¤ì¥ì™€ í•„ìš”í•œ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
    
    ì§ˆë¬¸: "{question}"
    
    [ì¶”ì¶œ ê·œì¹™]
    
    1. target_store_codes: ë¶„ì„ ëŒ€ìƒ ë§¤ì¥ëª… (í•œê¸€ í‚¤ì›Œë“œ)
       - âŒ ì ˆëŒ€ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì§€ ë§ˆì„¸ìš”. (No English Codes like 'SEOUL_GANGNAM')
       - ì§ˆë¬¸ì— ìˆëŠ” ë‹¨ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
       - "ê°•ë‚¨ì  ë§¤ì¶œ" -> ["ê°•ë‚¨"]
       - "ì„œìš¸ì´ë‘ ë¶€ì‚° ë¹„êµ" -> ["ì„œìš¸", "ë¶€ì‚°"]
       - "ì „ì²´", "ëª¨ë“ " -> ["ALL"]
       
    2. required_tables: ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì¡°íšŒí•´ì•¼ í•  í…Œì´ë¸” ë¦¬ìŠ¤íŠ¸ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)
       - "orders": ë©”ë‰´ íŒë§¤ëŸ‰, ì¸ê¸°/ë¹„ì¸ê¸° ë©”ë‰´ ì‹ë³„ (What)
       - "sales_daily": ë§¤ì¶œ ì¶”ì´, ë‚ ì”¨ ì •ë³´ í¬í•¨ (External Factor)
       - "reviews": íŒë§¤/ë§¤ì¶œì˜ 'ì›ì¸(Why)' ë¶„ì„, ê³ ê° ë°˜ì‘, ë§› í‰ê°€ (ì´ìœ /ë¶„ì„ ìš”ì²­ ì‹œ í•„ìˆ˜ í¬í•¨)
       
    [í…Œì´ë¸” ì„ íƒ ê°€ì´ë“œ]
    - "ì™œ ë§¤ì¶œì´ ì¤„ì—ˆì–´?" -> ["sales_daily", "reviews"] (ì¶”ì´ + ì›ì¸)
    - "ì•ˆ íŒ”ë¦° ë©”ë‰´ì™€ ì´ìœ " -> ["orders", "reviews"] (ë©”ë‰´ + ì›ì¸)
    - "ê·¸ëƒ¥ ë§¤ì¶œ ë³´ì—¬ì¤˜" -> ["sales_daily"]
       
    [ì¶œë ¥ ì˜ˆì‹œ]
    {{
        "target_store_codes": ["ê°•ë‚¨"], 
        "required_tables": ["sales_daily", "reviews"],
        "reason": "ê°•ë‚¨ì ì˜ ë§¤ì¶œ ì¶”ì´ì™€ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•¨"
    }}
    """
    try:
        response = await genai_generate_text(prompt)
        clean_text = response.replace("```json", "").replace("```", "").strip()
        parsed = json.loads(clean_text)
        return parsed
    except:
        return {"target_store_codes": ["ALL"], "required_tables": ["sales_daily", "orders"], "reason": "Error parsing"}

# ===== Step 3: Diagnosis Node (Multi-Store Support) =====
async def diagnosis_node(state: InquiryState) -> InquiryState:
    """
    [Sales Analysis V2] 
    1. ë§¤ì¥ Scope í™•ì¸ (ì„œìš¸/ë¶€ì‚°/ê°•ì›/ì „ì²´)
    2. ìµœê·¼ ë°ì´í„° ê¸°ì¤€ì¼(Anchor Date) ì‚°ì¶œ
    3. í•„ìš”í•œ í…Œì´ë¸”ë§Œ ê³¨ë¼ì„œ ë™ì  ì¿¼ë¦¬ (Orders / SalesDaily / Reviews)
    """
    if state["category"] != "sales":
        return state
        
    print(f"ğŸ•µï¸â€â™€ï¸ [Diagnosis V2] ë¶„ì„ ì‹œì‘: {state['question']}")
    
    # 1. ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì¶”ì¶œ (LLM)
    search_params = await extract_search_params(state['question'])
    
    target_store_codes = search_params.get("target_store_codes", ["ALL"])
    required_tables = search_params.get("required_tables", [])
    date_range_str = search_params.get("date_range", "DATE(o.ordered_at) >= DATE('now', '-7 days')")
    reason = search_params.get("reason", "")
    
    print(f"   ğŸ¯ íƒ€ê²Ÿ(List): {target_store_codes}, Tables: {required_tables}")
    
    # Store ID Mapping
    collected_data = {
        "scope": ", ".join(target_store_codes),
        "tables_used": required_tables,
        "period": "ìµœê·¼ 7ì¼ (ìë™ ì„¤ì •)" if "7 days" in date_range_str else "ì‚¬ìš©ì ì§€ì •",
        "reason": reason
    }
    
    try:
        # DB ì—°ê²° ë° ìŠ¤í† ì–´ ID ì¡°íšŒ (ê³µí†µ)
        store_codes = []
        target_ids = []
        target_store_id = None # ë‹¨ì¼ ìŠ¤í† ì–´ìš© (ë¹„ì „ìš©)

        q_stores = "SELECT store_id, store_name, region FROM stores"
        all_stores = await fetch_all(q_stores)
        print(f"ğŸ•µï¸ [Debug] DB Stores: {all_stores}") # ì‹¤ì œ DBì— ì–´ë–»ê²Œ ì €ì¥ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        
        # Scope Resolution (AI-Powered Matching)
        if "ALL" in target_store_codes:
            store_codes = [s['store_name'] for s in all_stores]
            target_ids = [s['store_id'] for s in all_stores]
        else:
            # [AI Matcher] ë‹¨ìˆœ ë¬¸ìì—´ ë¹„êµ ëŒ€ì‹  LLMì´ íŒë‹¨ (í•œê¸€/ì˜ì–´/ë³„ì¹­ ì™„ë²½ ëŒ€ì‘)
            match_prompt = f"""
            ë‹¹ì‹ ì€ ë°ì´í„° ë§¤ì¹­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
            ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ 'í‚¤ì›Œë“œ'ì™€ ì‹¤ì œ DBì— ìˆëŠ” 'ë§¤ì¥ ëª©ë¡'ì„ ë³´ê³ , ì˜ë„ì— ë§ëŠ” ë§¤ì¥ì˜ IDë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

            1. ì‚¬ìš©ì í‚¤ì›Œë“œ: {target_store_codes}
            2. DB ë§¤ì¥ ëª©ë¡: {json.dumps(all_stores, ensure_ascii=False)}

            [ë§¤ì¹­ ê·œì¹™]
            - "ê°•ë‚¨" -> "ì„œìš¸ ê°•ë‚¨ì " (O)
            - "SEOUL" -> "ì„œìš¸ ê°•ë‚¨ì " (O)
            - "ë³¸ì " -> "ì„œìš¸ ê°•ë‚¨ì " (ë§Œì•½ ê°•ë‚¨ì´ ë³¸ì ì´ë¼ë©´ ë¬¸ë§¥ìƒ íŒë‹¨, ë¶ˆí™•ì‹¤í•˜ë©´ Skip)
            - "ì†ì´ˆ" -> "ê°•ì› ì†ì´ˆì " (O)
            
            [Output JSON]
            ë°˜ë“œì‹œ ë§¤ì¹­ëœ store_id ë¦¬ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
            {{"matched_ids": [1, 3]}}
            """
            try:
                m_res = await genai_generate_text(match_prompt)
                m_clean = m_res.replace("```json", "").replace("```", "").strip()
                m_data = json.loads(m_clean)
                target_ids = m_data.get("matched_ids", [])
                
                # ë§¤ì¹­ëœ IDë¡œ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ì—­ì¶”ì 
                store_codes = [s['store_name'] for s in all_stores if s['store_id'] in target_ids]
                print(f"ğŸ¤– [AI Matcher] Mapped {target_store_codes} -> IDs: {target_ids} ({store_codes})")
                
            except Exception as e:
                print(f"âš ï¸ [AI Matcher] Error: {e}")
                # Fallback: ê¸°ì¡´ ë‹¨ìˆœ ë§¤ì¹­ (ì•ˆì „ì¥ì¹˜)
                for code in target_store_codes:
                    clean_code = code.replace(" ", "").strip()
                    for s in all_stores:
                        if clean_code and (clean_code in s['store_name'].replace(" ", "") or clean_code in (s['region'] or "")):
                             if s['store_id'] not in target_ids:
                                 target_ids.append(s['store_id'])
                                 store_codes.append(s['store_name'])
                            
        # [UI Fix] ì‹¤ì œ ë§¤ì¹­ëœ ë§¤ì¥ëª… ì „ë‹¬ (ì¤‘ìš”)
        if store_codes:
            collected_data["target_store_name"] = ", ".join(store_codes)
        else:
            collected_data["target_store_name"] = "ì „ì²´ ì§€ì  (ì‹ë³„ ì‹¤íŒ¨)" if "ALL" not in target_store_codes else "ì „ì²´ ì§€ì "
        
        # [Anchor Date Fix] ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ì‹¤ì œ ë§ˆì§€ë§‰ ë‚ ì§œ í™•ì¸
        # í˜„ì¬ ì‹œìŠ¤í…œ ì‹œê°„(2026ë…„)ê³¼ ë°ì´í„° ì‹œê°„(2025ë…„) ë¶ˆì¼ì¹˜ í•´ê²°
        anchor_date = None
        q_max_date = "SELECT MAX(sale_date) as last_date FROM sales_daily"
        if target_ids:
             ids_str = ",".join(map(str, target_ids))
             q_max_date += f" WHERE store_id IN ({ids_str})"
             
        try:
            date_rows = await fetch_all(q_max_date)
            if date_rows and date_rows[0]['last_date']:
                anchor_date = date_rows[0]['last_date']
                
                # date ê°ì²´ í™•ì¸ ë° ë³€í™˜
                if isinstance(anchor_date, str):
                    curr_date = datetime.strptime(anchor_date, "%Y-%m-%d").date()
                else:
                    curr_date = anchor_date
                    
                start_date = curr_date - timedelta(days=6) # 1ì£¼ì¼
                # [CRITICAL FIX] Postgres í˜¸í™˜ì„ ìœ„í•´ ëª…ì‹œì  ë‚ ì§œ ë¬¸ìì—´ ì‚¬ìš©
                date_range_str = f"'{start_date}' AND '{curr_date}'"
                print(f"ğŸ“… [Smart Period] ë°ì´í„° ê¸°ë°˜ ê¸°ê°„ ì¬ì„¤ì •: {start_date} ~ {curr_date}")
            else:
                print("âš ï¸ [Smart Period] ë°ì´í„°ê°€ ì—†ì–´ ê¸°ë³¸ ê¸°ê°„(ìµœê·¼ 7ì¼) ì‚¬ìš©")
                # Fallback: Postgres Syntax
                date_range_str = "CURRENT_DATE - INTERVAL '7 days' AND CURRENT_DATE"
        except Exception as e:
            print(f"âš ï¸ [Smart Period] Error: {e}")
            
        print(f"ğŸ” [Diagnosis] Effective Date Range: {date_range_str}")

        # (A) Sales Daily (ë§¤ì¶œ ì¶”ì´)
        if "sales_daily" in required_tables:
            where_sql = f"DATE(s.sale_date) BETWEEN {date_range_str}"
            if target_ids:
                ids_str = ",".join(map(str, target_ids))
                where_sql += f" AND s.store_id IN ({ids_str})"
            
            q_sales = f"""
                SELECT s.sale_date, st.store_name, SUM(s.total_sales) as total_sales, SUM(s.total_orders) as total_orders, MAX(s.weather_info) as weather_info
                FROM sales_daily s
                JOIN stores st ON s.store_id = st.store_id
                WHERE {where_sql}
                GROUP BY s.sale_date, st.store_name
                ORDER BY s.sale_date ASC
            """
            rows = await fetch_all(q_sales)
            collected_data["daily_trend"] = rows
            
            # Chart Data
            chart_data = []
            for r in rows:
                chart_data.append({
                    "date": r['sale_date'],
                    "store": r['store_name'],
                    "sales": float(r['total_sales']) if r['total_sales'] else 0,
                    "orders": int(r['total_orders']) if r['total_orders'] else 0
                })
            collected_data["chart_data"] = chart_data

        # (B) Orders (ë©”ë‰´ ë¶„ì„)
        # [Safety Lock] ë©”ë‰´ ë¶„ì„(Orders) ì‹œ ë¦¬ë·° ê°•ì œ ì¶”ê°€
        if "orders" in required_tables:
            if "reviews" not in required_tables:
                print("âš ï¸ [Auto-Fix] ë©”ë‰´ ë¶„ì„ì„ ìœ„í•´ Reviews í…Œì´ë¸” ê°•ì œ ì¶”ê°€")
                required_tables.append("reviews")
                
            where_sql = f"DATE(o.ordered_at) BETWEEN {date_range_str}"
            if target_ids:
                 ids_str = ",".join(map(str, target_ids))
                 where_sql += f" AND o.store_id IN ({ids_str})"
            
            q_menu = f"""
                SELECT 
                    m.menu_id,
                    m.menu_name, 
                    m.category, 
                    SUM(o.quantity) as qty, 
                    SUM(o.total_price) as rev
                FROM orders o
                JOIN menus m ON o.menu_id = m.menu_id
                WHERE {where_sql}
                GROUP BY m.menu_id, m.menu_name, m.category
                ORDER BY qty DESC
                LIMIT 5
            """
            # 1. Top 5 Fetch
            rows_top = await fetch_all(q_menu)
            print(f"ğŸ“Š [Diagnosis] Top Menus Fetched: {len(rows_top)}")
            
            # 2. Worst 5 Fetch
            q_worst = q_menu.replace("DESC", "ASC").replace("LIMIT 5", "LIMIT 5")
            rows_worst = await fetch_all(q_worst)
            print(f"ğŸ“Š [Diagnosis] Worst Menus Fetched: {len(rows_worst)}")
            
            # 3. Review Binding Logic
            all_target_menus = rows_top + rows_worst
            target_menu_ids = [r['menu_id'] for r in all_target_menus]
            
            menu_review_map = {} 
            
            if target_menu_ids:
                 ids_str_menu = ",".join(map(str, set(target_menu_ids)))
                 q_deep = f"""
                    SELECT o.menu_id, r.rating, r.review_text, o.ordered_at
                    FROM reviews r
                    JOIN orders o ON r.order_id = o.order_id
                    WHERE o.menu_id IN ({ids_str_menu}) 
                    AND DATE(o.ordered_at) BETWEEN {date_range_str}
                 """
                 
                 # [Critial Fix] ì§€ì  í•„í„°ë§ ëˆ„ë½ ìˆ˜ì •
                 if target_ids:
                     ids_str_store = ",".join(map(str, target_ids))
                     q_deep += f" AND o.store_id IN ({ids_str_store})"
                     
                 q_deep += " ORDER BY r.created_at DESC"
                 deep_reviews = await fetch_all(q_deep)
                 print(f"ğŸ’¬ [Diagnosis] Bound Reviews Fetched: {len(deep_reviews)}")
                 
                 # UI ì¦ê±°ìš© ì €ì¥
                 collected_data["menu_specific_reviews"] = deep_reviews
                 
                 for dr in deep_reviews:
                     mid = dr['menu_id']
                     if mid not in menu_review_map:
                         menu_review_map[mid] = []
                     menu_review_map[mid].append(f"â­{dr['rating']}: {dr['review_text']}")
            
            # 4. Attach to Menu Data
            for r in rows_top:
                r['related_reviews'] = menu_review_map.get(r['menu_id'], [])[:10]
            for r in rows_worst:
                r['related_reviews'] = menu_review_map.get(r['menu_id'], [])[:10]

            collected_data["top_selling_menus"] = rows_top
            collected_data["low_selling_menus"] = rows_worst

        # (C) Reviews (ì¼ë°˜ ì¡°íšŒ)
        if "reviews" in required_tables:
            # Join with orders to get date & store filtering
            where_sql = f"DATE(o.ordered_at) BETWEEN {date_range_str}"
            if target_ids:
                ids_str = ",".join(map(str, target_ids))
                where_sql += f" AND o.store_id IN ({ids_str})"
            
            q_review = f"""
                SELECT s.store_name, r.rating, r.review_text, o.ordered_at
                FROM reviews r
                JOIN orders o ON r.order_id = o.order_id
                JOIN stores s ON o.store_id = s.store_id
                WHERE {where_sql}
                ORDER BY o.ordered_at DESC
                LIMIT 500
            """
            rows = await fetch_all(q_review)
            collected_data["recent_reviews"] = rows
            print(f"ğŸ’¬ [Diagnosis] Recent Reviews Fetched: {len(rows)}")

    except Exception as e:
        print(f"âŒ [Diagnosis] Critical Error: {e}")
        collected_data["error"] = str(e)
        collected_data["summary_text"] = f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        
    # 3. Summary Generation (LLMì„ ìœ„í•œ ìš”ì•½ í…ìŠ¤íŠ¸)
    # [Contextual Binding] ë©”ë‰´ì™€ ë¦¬ë·°ë¥¼ í•¨ê»˜ ì œê³µ
    summary_text = f"=== ğŸ“Š ë¶„ì„ ë¦¬í¬íŠ¸ ({', '.join(store_codes)}) ===\n"
    summary_text += f"ê¸°ê°„: {date_range_str}\n\n"
    
    if "daily_trend" in collected_data:
        summary_text += "[ì¼ë³„ ë§¤ì¶œ ë°ì´í„° (ì§€ì ë³„ êµ¬ë¶„)]\n"
        for r in collected_data["daily_trend"]:
            sales_val = float(r['total_sales']) if r['total_sales'] else 0
            weather = r.get('weather_info', '-')
            summary_text += f"- [{r['sale_date']}] {r['store_name']}: {sales_val:,.0f}ì› (ì£¼ë¬¸ {r['total_orders']}ê±´, ë‚ ì”¨ {weather})\n"

    if "top_selling_menus" in collected_data:
        summary_text += "\n[í†µí•© ì¸ê¸° ë©”ë‰´ Top 5 (Best)]\n"
        for m in collected_data["top_selling_menus"]:
            summary_text += f"- {m['menu_name']} ({m['category']}): {m['qty']}ê°œ íŒë§¤, {int(m['rev']):,}ì›\n"
            if 'related_reviews' in m and m['related_reviews']:
                reviews_str = " / ".join(m['related_reviews'])
                summary_text += f"  (ğŸ” ê³ ê° ë¦¬ë·°: {reviews_str})\n"

    if "low_selling_menus" in collected_data:
        summary_text += "\n[í†µí•© íŒë§¤ ì €ì¡° ë©”ë‰´ Top 5 (Worst)]\n"
        for m in collected_data["low_selling_menus"]:
            summary_text += f"- {m['menu_name']} ({m['category']}): {m['qty']}ê°œ íŒë§¤, {int(m['rev']):,}ì›\n"
            if 'related_reviews' in m and m['related_reviews']:
                reviews_str = " / ".join(m['related_reviews'])
                summary_text += f"  (ğŸ” ê³ ê° ë¦¬ë·°: {reviews_str})\n"
                
    if "recent_reviews" in collected_data and isinstance(collected_data["recent_reviews"], list):
        summary_text += "\n[ìµœê·¼ ê³ ê° ë¦¬ë·° ë°ì´í„° (ë§¤ì¥ ì „ì²´)]\n"
        for r in collected_data["recent_reviews"][:20]: # ìƒìœ„ 20ê°œë§Œ
            s_name = r.get('store_name', '')
            summary_text += f"- [{s_name}] â­{r.get('rating')}: {r.get('review_text')}\n"

    collected_data["summary_text"] = summary_text
    
    # 5. Result for Chat UI Chart (Chart Data Formatting)
    if "daily_trend" in collected_data:
        collected_data["chart_setup"] = {"title": f"ì§€ì ë³„ ë§¤ì¶œ ì¶”ì´ ë¹„êµ ({', '.join(store_codes)})"}
        total_sales = sum([float(r['total_sales']) for r in collected_data["daily_trend"] if r['total_sales']])
        total_orders = sum([int(r['total_orders']) for r in collected_data["daily_trend"] if r['total_orders']])
        
        collected_data["key_metrics"] = {
            "period": "ìµœê·¼ 7ì¼",
            "total_sales": total_sales,
            "total_orders": total_orders
        }

    # ê°„ë‹¨ ì§„ë‹¨ ì½”ë©˜íŠ¸ (íƒ€ì´í‹€ìš©)
    collected_data["diagnosis_result"] = f"ë¶„ì„ ì™„ë£Œ: {', '.join(store_codes)} (ìµœê·¼ 7ì¼)"

    state["sales_data"] = collected_data
    return state
