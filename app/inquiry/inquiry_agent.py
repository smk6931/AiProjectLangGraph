"""
í”„ëœì°¨ì´ì¦ˆ ê°€ë§¹ì  ë¬¸ì˜ ì‘ë‹µ ì—ì´ì „íŠ¸ (LangGraph)

Router ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬:
1. ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜ (ë§¤ì¶œ/ë§¤ë‰´ì–¼/ì •ì±…)
2. ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ì†ŒìŠ¤ ê²€ìƒ‰ (SQL/RAG)
3. ì¢…í•© ë‹µë³€ ìƒì„±
4. DB ì €ì¥
"""

from typing import TypedDict, List, Dict, Any, Annotated
from langgraph.graph import StateGraph, END
from app.clients.genai import genai_generate_text
from app.core.db import fetch_all
from app.inquiry.inquiry_service import save_inquiry
import json
from datetime import datetime, timedelta

# ===== ë°ì´í„° ê²€ìƒ‰ìš© íŒŒë¼ë¯¸í„° ì¶”ì¶œ í•¨ìˆ˜ =====
async def extract_search_params(question: str):
    """
    ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ ì¡°ê±´(ì§€ì ëª…, ê¸°ê°„ ë“±)ì„ ì¶”ì¶œ
    """
    prompt = f"""
    ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë°ì´í„° ê²€ìƒ‰ ì¡°ê±´ì„ JSONìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
    
    ì§ˆë¬¸: "{question}"
    
    [ì¶”ì¶œ ê·œì¹™]
    1. target_store_name: ì§ˆë¬¸ì— 'ê°•ë‚¨ì ', 'í•´ìš´ëŒ€' ë“± ì§€ì ëª…ì´ë‚˜ 'ì„œìš¸', 'ë¶€ì‚°' ë“± ì§€ì—­ëª…ì´ ìˆìœ¼ë©´ ì¶”ì¶œ (ì—†ìœ¼ë©´ null)
    2. days: ì¡°íšŒ ê¸°ê°„ (ì¼ìˆ˜). 
       - "ì–´ì œ" -> 1
       - "ì§€ë‚œì£¼", "ì¼ì£¼ì¼" -> 7
       - "ìµœê·¼ 3ì¼" -> 3
       - "ì´ë²ˆë‹¬", "30ì¼" -> 30
       - ì–¸ê¸‰ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 7
    3. need_reviews: ë¦¬ë·° ë°ì´í„°ê°€ í•„ìš”í•œì§€ ì—¬ë¶€ (true/false)

    [ì¶œë ¥ ì˜ˆì‹œ]
    {{
        "target_store_name": "í•´ìš´ëŒ€",
        "days": 7,
        "need_reviews": true
    }}
    """
    try:
        response = await genai_generate_text(prompt)
        # JSON íŒŒì‹± íŠ¸ë¦­ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ëŸ­ ì œê±°)
        clean_text = response.replace("```json", "").replace("```", "").strip()
        parsed = json.loads(clean_text)
        if isinstance(parsed, dict):
            return parsed
        else:
            return {"target_store_name": None, "days": 7, "need_reviews": False}
    except:
        return {"target_store_name": None, "days": 7, "need_reviews": False}


# ===== Step 1: State ì •ì˜ =====
class InquiryState(TypedDict):
    """ì—ì´ì „íŠ¸ ìƒíƒœ ê´€ë¦¬"""
    store_id: int
    question: str
    category: str  # Routerê°€ ë¶„ë¥˜í•œ ì¹´í…Œê³ ë¦¬
    
    # ê° ë…¸ë“œì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°
    sales_data: Dict[str, Any]
    manual_data: List[str]
    policy_data: List[str]
    
    # ìµœì¢… ê²°ê³¼
    final_answer: str
    inquiry_id: int
    diagnosis_result: str # ìƒˆë¡œ ì¶”ê°€ (ì§„ë‹¨ ê²°ê³¼ ìš”ì•½)


# ===== Step 2: Router Node (ì§ˆë¬¸ ë¶„ë¥˜) =====
async def router_node(state: InquiryState) -> InquiryState:
    """
    ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    - sales: ë§¤ì¶œ, ì„±ê³¼, í†µê³„ ê´€ë ¨
    - manual: ê¸°ê¸° ì‚¬ìš©ë²•, ë ˆì‹œí”¼, ê¸°ìˆ  ì§€ì›
    - policy: ìš´ì˜ ê·œì •, ê³ ê° ì‘ëŒ€, ë³¸ì‚¬ ì •ì±…
    """
    question = state["question"]
    
    prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì¹´í…Œê³ ë¦¬ë¥¼ ì •í™•íˆ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì„¸ìš”.

ì§ˆë¬¸: {question}

ì¹´í…Œê³ ë¦¬:
- sales: ë§¤ì¶œ, íŒë§¤ëŸ‰, í†µê³„, ìˆœìœ„ ë“± ìˆ«ì ë°ì´í„° ê´€ë ¨
- manual: ê¸°ê¸° ì‚¬ìš©ë²•, ì²­ì†Œ ë°©ë²•, ë ˆì‹œí”¼, ê³ ì¥ ìˆ˜ë¦¬
- policy: ìš´ì˜ ê·œì •, ê³ ê° ì‘ëŒ€, í™˜ë¶ˆ ì •ì±…, ë³µì¥ ê·œì •

JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€:
{{"category": "sales|manual|policy"}}
"""
    
    result = await genai_generate_text(prompt)
    parsed = json.loads(result)
    
    state["category"] = parsed["category"]
    print(f"ğŸ” [Router] ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬: {parsed['category']}")
    
    return state


# ===== Step 3: Diagnosis Node (ë§¤ì¶œ ì§„ë‹¨ & ì›ì¸ ë¶„ì„) =====
async def diagnosis_node(state: InquiryState) -> InquiryState:
    """ë§¤ì¶œ í•˜ë½ ì›ì¸ ì§„ë‹¨ ë° ì¢…í•© ë¶„ì„ (Sales + Weather + Reviews)"""
    if state["category"] != "sales":
        return state
        
    print(f"ğŸ•µï¸â€â™€ï¸ [Diagnosis] ë§¤ì¶œ ì§„ë‹¨ ì‹œì‘: {state['question']}")
    
    # 1. ê²€ìƒ‰ ì¡°ê±´ ì¶”ì¶œ
    params = await extract_search_params(state['question'])
    target_store_id = state["store_id"]
    days = params.get("days", 7)
    
    # ---------------------------------------------------------
    # [Smart Store Matcher] ì§€ì ëª…/ì§€ì—­ëª… ë§¤ì¹­ ë¡œì§ ê°•í™”
    # ---------------------------------------------------------
    start_search_name = params.get("target_store_name")
    
    if start_search_name:
        print(f"   ğŸ” ì§€ì  ê²€ìƒ‰ ì‹œë„: '{start_search_name}'")
        
        # 1. ì „ì²´ ë§¤ì¥ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ë°ì´í„° ì–‘ì´ ì ìœ¼ë¯€ë¡œ ì „ì²´ ë¡œë“œ í›„ ë§¤ì¹­ì´ ì •í™•í•¨)
        all_stores_query = "SELECT store_id, store_name, city FROM stores"
        all_stores = await fetch_all(all_stores_query)
        
        # 2. ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° (Python ë¡œì§)
        # í‚¤ì›Œë“œê°€ store_nameì´ë‚˜ cityì— í¬í•¨ë˜ë©´ ë§¤ì¹­ í›„ë³´
        best_match = None
        best_score = 0
        
        # ê²€ìƒ‰ì–´ ì •ì œ ("ì ", "ì§€ì " ë“± ì œê±°)
        keyword = start_search_name.replace("ì§€ì ", "").replace("ì ", "").strip()
        
        for store in all_stores:
            score = 0
            s_name = store['store_name']
            s_city = store['city']
            
            # (1) ì •í™•íˆ í¬í•¨ë˜ëŠ” ê²½ìš°
            if keyword in s_name: score += 3
            if keyword in s_city: score += 2
            
            # (2) ë¶€ë¶„ ì¼ì¹˜ (2ê¸€ì ì´ìƒ ê²¹ì¹¨) - ê°„ë‹¨í•œ ë¡œì§
            # ì‹¤ì œë¡œëŠ” difflib ë“±ì„ ì“¸ ìˆ˜ë„ ìˆì§€ë§Œ, ì—¬ê¸°ì„  í¬í•¨ ì—¬ë¶€ê°€ ì ¤ í™•ì‹¤í•¨
            
            if score > best_score:
                best_score = score
                best_match = store
                
        # 3. ê²°ê³¼ ë°˜ì˜
        if best_match and best_score > 0:
            target_store_id = best_match["store_id"]
            state["store_id"] = target_store_id
            print(f"   âœ… ì§€ì  ë§¤ì¹­ ì„±ê³µ: '{start_search_name}' -> {best_match['store_name']} (ID {target_store_id})")
        else:
            print(f"   âŒ ì§€ì  ë§¤ì¹­ ì‹¤íŒ¨: '{start_search_name}' (DBì— ìœ ì‚¬í•œ ì§€ì ì´ ì—†ìŒ)")
            # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ, ì—‰ëš±í•œ ì§€ì (ê¸°ë³¸ê°’) ë°ì´í„°ë¥¼ ë³´ì—¬ì£¼ë©´ ì•ˆë¨.
            # ëª…í™•íˆ "ì°¾ì„ ìˆ˜ ì—†ìŒ"ì„ ë‹µë³€í•˜ë„ë¡ ìœ ë„í•´ì•¼ í•¨.
            state["sales_data"] = {
                "summary_text": f"ì£„ì†¡í•©ë‹ˆë‹¤. '{start_search_name}'ì— í•´ë‹¹í•˜ëŠ” ì§€ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê²€ìƒ‰ëœ í‚¤ì›Œë“œ: {keyword})",
                "recent_sales": [],
                "store_name": "ì•Œ ìˆ˜ ì—†ìŒ",
                "diagnosis_result": "ì§€ì  ì‹ë³„ ë¶ˆê°€"
            }
            return state
            
    # ---------------------------------------------------------
    
    # ë‚ ì§œ ê³„ì‚° (ë¹„êµ ë¶„ì„ì„ ìœ„í•´ 2ë°° ê¸°ê°„ ì¡°íšŒ)
    try:
        days = int(days)
    except:
        days = 7
        
    end_date = datetime.now()
    start_date = (end_date - timedelta(days=days)).strftime("%Y-%m-%d")
    prev_start_date = (end_date - timedelta(days=days*2)).strftime("%Y-%m-%d")

    # 2. ë§¤ì¶œ & ë‚ ì”¨ ë°ì´í„° ì¡°íšŒ (í˜„ì¬ ê¸°ê°„ vs ì§ì „ ê¸°ê°„)
    # ì§ì „ ê¸°ê°„ê¹Œì§€ í¬í•¨í•´ì„œ ë„‰ë„‰í•˜ê²Œ ì¡°íšŒ
    sales_query = f"""
        SELECT sale_date, total_sales, total_orders, weather_info 
        FROM sales_daily 
        WHERE store_id = {target_store_id} 
          AND sale_date >= '{prev_start_date}'
        ORDER BY sale_date DESC
    """
    sales_rows = await fetch_all(sales_query)
    
    # ë°ì´í„° ë¶„ë¦¬ (ì´ë²ˆ ê¸°ê°„ vs ì§€ë‚œ ê¸°ê°„)
    current_period = []
    prev_period = []
    
    import pandas as pd
    threshold_date = pd.to_datetime(start_date).date()
    
    for row in sales_rows:
        try:
            row_date = row["sale_date"] # date ê°ì²´ë¼ê³  ê°€ì •
        except:
            row_date = datetime.strptime(str(row["sale_date"]), "%Y-%m-%d").date()
            
        if row_date >= threshold_date:
            current_period.append(row)
        else:
            prev_period.append(row)
            
    # ë§¤ì¶œ ì¦ê°ìœ¨ ê³„ì‚°
    curr_total = sum([r['total_sales'] for r in current_period])
    prev_total = sum([r['total_sales'] for r in prev_period])
    
    growth_rate = 0
    if prev_total > 0:
        growth_rate = ((curr_total - prev_total) / prev_total) * 100
        
    print(f"   ğŸ“‰ ë§¤ì¶œ ë¶„ì„: ì´ë²ˆ {days}ì¼ {curr_total:,.0f}ì› vs ì§€ë‚œ {days}ì¼ {prev_total:,.0f}ì› (ë³€ë™ë¥ : {growth_rate:.1f}%)")

    # 3. ë°ì´í„° í¬ë§·íŒ…
    sales_text = f"=== ë§¤ì¶œ ì§„ë‹¨ ë¦¬í¬íŠ¸ (ì§€ì ID: {target_store_id}) ===\n"
    sales_text += f"ê¸°ê°„: ìµœê·¼ {days}ì¼ ({start_date} ~ Today)\n"
    sales_text += f"ë§¤ì¶œ ë³€ë™: {curr_total:,.0f}ì› (ì „ë¶„ê¸° ëŒ€ë¹„ {growth_rate:+.1f}% {'ìƒìŠ¹' if growth_rate >=0 else 'í•˜ë½'})\n"
    
    recent_sales_data = []
    for row in current_period:
        w_info = row['weather_info'] if row.get('weather_info') else "ë‚ ì”¨ì •ë³´ì—†ìŒ"
        recent_sales_data.append({
            "date": str(row["sale_date"]),
            "sales": float(row["total_sales"]),
            "orders": row["total_orders"],
            "weather": w_info
        })
        sales_text += f"- {row['sale_date']}: {row['total_sales']:,.0f}ì› / {row['total_orders']}ê±´ ({w_info})\n"

    # 4. ë¦¬ë·° ë°ì´í„° ì¡°íšŒ (ë§¤ì¶œ í•˜ë½ ì‹œ ë˜ëŠ” ì§„ë‹¨ ìš”ì²­ ì‹œ ë¬´ì¡°ê±´ ì¡°íšŒ)
    # ë§¤ì¶œì´ ë–¨ì–´ì¡Œê±°ë‚˜(-), ì§ˆë¬¸ì— 'ì›ì¸', 'ì§„ë‹¨', 'ì´ìœ ' ë“±ì´ í¬í•¨ë˜ë©´ ë¦¬ë·°ë¥¼ ê¹Šê²Œ íŒŒë´„
    need_deep_dive = growth_rate < 0 or any(x in state["question"] for x in ["ì›ì¸", "ì´ìœ ", "ì§„ë‹¨", "ë¶„ì„", "ë¬¸ì œ"])
    
    # [ì‚­ì œë¨: ê¸°ì¡´ì˜ ë‹¨ìˆ  ì§€ì  ê²€ìƒ‰ ë¡œì§ ì œê±°]
    # ìœ„ì—ì„œ ì´ë¯¸ Smart Store Matcherë¡œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œê±°í•¨.

    # 3. ë‚ ì§œ ê³„ì‚° (ì´ ì£¼ì„ì€ ì›ë˜ ì½”ë“œì˜ ì”ì¬ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬´ì‹œ)
    
    review_summary = ""
    if need_deep_dive or params.get("need_reviews", False):
         print("   ğŸ§ ë§¤ì¶œ ë¶€ì§„/ì§„ë‹¨ ìš”ì²­ ê°ì§€ -> ë¦¬ë·° ì •ë°€ ë¶„ì„ ìˆ˜í–‰")
         review_query = f"""
            SELECT rating, review_text, created_at 
            FROM reviews 
            WHERE store_id = {target_store_id} 
              AND created_at >= '{prev_start_date}'
            ORDER BY created_at DESC 
            LIMIT 10
         """
         review_rows = await fetch_all(review_query)
         review_summary = f"\n=== ê³ ê° ë¦¬ë·° ë¶„ì„ (ë§¤ì¶œ ì˜í–¥ ìš”ì¸) ===\n"
         if not review_rows:
             review_summary += "íŠ¹ì´í•œ ë¦¬ë·° ì—†ìŒ.\n"
         else:
             for row in review_rows:
                 review_summary += f"- {row['created_at']} (â­{row['rating']}): {row['review_text']}\n"
                 
         sales_text += review_summary

    # stateì— ì €ì¥
    state["sales_data"] = {
        "summary_text": sales_text,
        "recent_sales": recent_sales_data,
        "reviews": review_summary,
        "diagnosis_result": f"ë§¤ì¶œ {growth_rate:.1f}% ë³€ë™"
    }
    
    return state


# ===== Step 4: Manual RAG Node (ë§¤ë‰´ì–¼ ê²€ìƒ‰) =====
async def manual_node(state: InquiryState) -> InquiryState:
    """ë§¤ë‰´ì–¼ DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (Vector Search)"""
    if state["category"] != "manual":
        return state
    
    question = state["question"]
    
    # OpenAI Embeddingsë¡œ ì§ˆë¬¸ ë²¡í„°í™”
    from langchain_openai import OpenAIEmbeddings
    embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")
    question_vector = embeddings_model.embed_query(question)
    
    # pgvector ìœ ì‚¬ë„ ê²€ìƒ‰ (ì½”ì‚¬ì¸ ê±°ë¦¬ ê¸°ì¤€ Top 3)
    # distanceê°€ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬í•¨
    query = f"""
    SELECT title, content, category,
           embedding <=> '{question_vector}'::vector AS distance
    FROM manuals
    ORDER BY distance
    LIMIT 3
    """
    
    rows = await fetch_all(query)
    
    # ê²€ìƒ‰ ê²°ê³¼ ë° ìµœì†Œ ê±°ë¦¬ ì €ì¥
    min_distance = 1.0 # ê¸°ë³¸ê°’ (ë¶ˆì¼ì¹˜)
    if rows:
        min_distance = min([r['distance'] for r in rows])
        
    state["manual_data"] = [
        f"[{row['title']}] (ìœ ì‚¬ë„: {1 - row['distance']:.2f})\n{row['content']}"
        for row in rows
    ]
    # ìƒíƒœì— ê²€ìƒ‰ í’ˆì§ˆ ì ìˆ˜(ê±°ë¦¬) ì €ì¥ (ì„ì‹œ í•„ë“œ í™œìš© ë˜ëŠ” state í™•ì¥ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„  meta dict ê°™ì€ê±¸ ì“°ê±°ë‚˜ ê°„ë‹¨íˆ ì „ì—­ ë³€ìˆ˜ì²˜ëŸ¼ ì²˜ë¦¬)
    # ì—¬ê¸°ì„œëŠ” stateì— ì§ì ‘ ì €ì¥í•˜ê¸° ìœ„í•´ TypedDictë¥¼ ë¬´ì‹œí•˜ê³  ëŸ°íƒ€ì„ì— ì¶”ê°€í•˜ê±°ë‚˜, ë¯¸ë¦¬ ì •ì˜í•´ì•¼í•¨.
    # í¸ì˜ìƒ sales_data ë‚´ë¶€ì— ë©”íƒ€ë°ì´í„°ë¡œ ìˆ¨ê¸°ê±°ë‚˜, ìƒˆë¡œìš´ í•„ë“œë¥¼ ì¶”ê°€í•˜ëŠ”ê²Œ ì •ì„.
    # ê°„ë‹¨íˆ existing fieldì¸ 'diagnosis_result'ë¥¼ ë‹¤ìš©ë„ ë©”íƒ€ í•„ë“œë¡œ í™œìš©í•´ ê¼¼ìˆ˜ë¥¼ ë¶€ë¦¬ê±°ë‚˜, 
    # ì •ì„ëŒ€ë¡œ State í´ë˜ìŠ¤ ìˆ˜ì •ì´ í•„ìš”í•¨. ì—¬ê¸°ì„  State ìˆ˜ì • ì—†ì´ sales_data ë”•ì…”ë„ˆë¦¬ì— 'search_quality' í‚¤ë¥¼ ë„£ì–´ ì „ë‹¬.
    
    if "search_meta" not in state: state["search_meta"] = {}
    state["search_meta"] = {"min_distance": min_distance, "source": "manual_db"}
    
    print(f"ğŸ“– [Manual] ê²€ìƒ‰ ì™„ë£Œ (Min Distance: {min_distance:.4f})")
    return state


# ===== Step 5: Policy RAG Node (ì •ì±… ê²€ìƒ‰) =====
async def policy_node(state: InquiryState) -> InquiryState:
    """ìš´ì˜ ì •ì±… ë§¤ë‰´ì–¼ ê²€ìƒ‰ (Policies í…Œì´ë¸” ì¡°íšŒ)"""
    if state["category"] != "policy":
        return state
    
    question = state["question"]
    
    from langchain_openai import OpenAIEmbeddings
    embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")
    question_vector = embeddings_model.embed_query(question)
    
    query = f"""
    SELECT title, content, category,
           embedding <=> '{question_vector}'::vector AS distance
    FROM policies
    ORDER BY distance
    LIMIT 3
    """
    
    rows = await fetch_all(query)
    
    min_distance = 1.0
    if rows:
        min_distance = min([r['distance'] for r in rows])
        
    state["policy_data"] = [
        f"[{row['title']}] (ìœ ì‚¬ë„: {1 - row['distance']:.2f})\n{row['content']}"
        for row in rows
    ]
    
    state["search_meta"] = {"min_distance": min_distance, "source": "policy_db"}
    
    print(f"ğŸ“œ [Policy] ê²€ìƒ‰ ì™„ë£Œ (Min Distance: {min_distance:.4f})")
    return state


# ===== Step 5.5: Web Search Node (ì™¸ë¶€ ê²€ìƒ‰) =====
# ===== Step 5.5: Web Search Node (ì™¸ë¶€ ê²€ìƒ‰) =====
async def web_search_node(state: InquiryState) -> InquiryState:
    """ë‚´ë¶€ DB ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì™¸ë¶€ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ (Tavily AI Search + Self-Correction)"""
    question = state["question"]
    print(f"ğŸŒ [Tavily Search] ë‚´ë¶€ ë¬¸ì„œ ë¶€ì¡± -> ì™¸ë¶€ ê²€ìƒ‰ ì „í™˜: {question}")
    
    # ğŸ”‘ Tavily API í‚¤ ì…ë ¥
    TAVILY_API_KEY = "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"
    
    # if TAVILY_API_KEY == "YOUR_TAVILY_KEY":
    #     state["manual_data"] = ["âŒ Tavily API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."]
    #     return state

    try:
        from tavily import TavilyClient
        tavily = TavilyClient(api_key=TAVILY_API_KEY)
        
        # 1ì°¨ ê²€ìƒ‰ ì‹œë„ (êµ¬ì²´ì  ì¿¼ë¦¬)
        target_query = f"ì¹´í˜ í”„ëœì°¨ì´ì¦ˆ {question}"
        response = tavily.search(query=target_query, search_depth="basic", max_results=5)
        raw_results = response.get('results', [])
        
        # ğŸ”„ Self-Correction: ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¿¼ë¦¬ ë‹¨ìˆœí™” í›„ ì¬ì‹œë„
        if not raw_results:
            print(f"ğŸ”„ [Self-Correction] '{target_query}' ê²°ê³¼ ì—†ìŒ -> '{question}' ìœ¼ë¡œ ì¬ê²€ìƒ‰")
            # ì ‘ë‘ì‚¬ ì œê±°í•˜ê³  ì§ˆë¬¸ ìì²´ë¡œ ê²€ìƒ‰
            response = tavily.search(query=question, search_depth="basic", max_results=5)
            raw_results = response.get('results', [])
        
        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_list = []
        for item in raw_results:
            title = item.get('title', 'ì œëª© ì—†ìŒ')
            url = item.get('url', '#')
            content = item.get('content', '')
            formatted_list.append(f"Title: {title}\nLink: {url}\nSnippet: {content}\n")
        
        if not formatted_list:
             state["manual_data"] = ["Tavily ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (ì¬ê²€ìƒ‰ í¬í•¨)"]
        else:
             formatted_results = "[ì™¸ë¶€ ì›¹ ê²€ìƒ‰ ê²°ê³¼ (Tavily)]\n" + "\n---\n".join(formatted_list)
             state["manual_data"] = [formatted_results]
        
        state["search_meta"] = {"source": "web_search", "min_distance": 0.0}
        
    except Exception as e:
        print(f"âŒ Tavily ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        state["manual_data"] = [f"ì™¸ë¶€ ê²€ìƒ‰ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (Error: {str(e)})"]
        
    return state


# ===== Step 6: Answer Synthesis Node (ë‹µë³€ ìƒì„±) =====
async def answer_node(state: InquiryState) -> InquiryState:
    """ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±"""
    question = state["question"]
    category = state["category"]
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = ""
    if category == "sales":
        context = f"ë§¤ì¶œ ë°ì´í„°:\n{json.dumps(state.get('sales_data', {}), ensure_ascii=False, indent=2)}"
    elif category == "manual":
        context = "\n\n".join(state.get("manual_data", []))
    elif category == "policy":
        context = "\n\n".join(state.get("policy_data", []))
    
    prompt = f"""
ë‹¹ì‹ ì€ í”„ëœì°¨ì´ì¦ˆ ë³¸ì‚¬ì˜ ì¹œì ˆí•œ AI ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.
ì§ˆë¬¸ì— ëŒ€í•´ ì•„ë˜ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

**ì¤‘ìš”: ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ì„ ì—„ê²©íˆ ì§€ì¼œì„œ ë‹µë³€í•˜ì„¸ìš”.**

[Category: sales ì¼ ë•Œ]
{{
  "type": "sales",
  "summary": "ë§¤ì¶œ ì¶”ì´ì™€ íŠ¹ì´ì‚¬í•­ì— ëŒ€í•œ ì¹œì ˆí•œ ìš”ì•½ ë©˜íŠ¸ (3ë¬¸ì¥ ì´ë‚´)",
  "data": [
      {{ "date": "YYYY-MM-DD", "sales": 150000, "orders": 25 }},
      ... (ë°ì´í„° ê·¸ëŒ€ë¡œ ë³µì‚¬)
  ]
}}

[Category: manual ë˜ëŠ” policy ì¼ ë•Œ]
{{
  "type": "general",
  "title": "ê´€ë ¨ ë§¤ë‰´ì–¼/ê·œì • ì œëª©",
  "content": "í•µì‹¬ ë‚´ìš© ìš”ì•½ ë° ìƒì„¸ ì„¤ëª… (Markdown í˜•ì‹, ì¤„ë°”ê¿ˆì€ \\n ì‚¬ìš©)"
}}

ì§ˆë¬¸: {question}
ì¹´í…Œê³ ë¦¬: {category}

ì°¸ê³  ìë£Œ:
{context}
"""
    
    answer = await genai_generate_text(prompt)
    state["final_answer"] = answer
    
    print(f"âœ… [Answer] ë‹µë³€ ìƒì„± ì™„ë£Œ ({len(answer)}ì)")
    return state


# ===== Step 7: Save Node (DB ì €ì¥) =====
async def save_node(state: InquiryState) -> InquiryState:
    """ì§ˆë¬¸ê³¼ ë‹µë³€ì„ DBì— ì €ì¥"""
    inquiry_id = save_inquiry(
        store_id=state["store_id"],
        category=state["category"],
        question=state["question"],
        answer=state["final_answer"]
    )
    
    state["inquiry_id"] = inquiry_id
    print(f"ğŸ’¾ [Save] DB ì €ì¥ ì™„ë£Œ (ID: {inquiry_id})")
    
    return state


# ===== Step 6: Answer Synthesis Node (ë‹µë³€ ìƒì„± - Structured) =====
async def answer_node_v2(state: InquiryState) -> InquiryState:
    """ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì¡°í™”ëœ JSON ë‹µë³€ ìƒì„±"""
    question = state["question"]
    category = state["category"]
    
    # 1. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_text = ""
    is_web_search = state.get("search_meta", {}).get("source") == "web_search"
    
    if category == "sales":
        if "sales_data" in state and state["sales_data"]:
             context_text = f"ë§¤ì¶œ ì§„ë‹¨ ê²°ê³¼:\n{state['sales_data'].get('diagnosis_result', '')}\n\nìƒì„¸ ë°ì´í„°:\n{state['sales_data'].get('summary_text', '')}"
    else:
        # manual / policy ë°ì´í„° í†µí•©
        docs = state.get("manual_data", []) + state.get("policy_data", [])
        context_text = "\n\n".join(docs)
    
    # 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (JSON ê°•ì œ)
    system_prompt = (
        "ë‹¹ì‹ ì€ í”„ëœì°¨ì´ì¦ˆ ë§¤ì¥ ê´€ë¦¬ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. "
        "ì§ˆë¬¸ì— ëŒ€í•´ ìˆ˜ì§‘ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”. "
        "ë°˜ë“œì‹œ ì•„ë˜ **JSON í¬ë§·**ìœ¼ë¡œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´(` ```json `)ì„ ì“°ì§€ ë§ê³  ìˆœìˆ˜ JSON ë¬¸ìì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n\n"
        "{\n"
        '  "summary": "í•µì‹¬ ë‚´ìš©ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ (ëª…í™•í•˜ê²Œ)",\n'
        '  "detail": "ìƒì„¸í•œ ë‹µë³€ ë‚´ìš© (ë§ˆí¬ë‹¤ìš´ í¬ë§· í™œìš© ê°€ëŠ¥, ì¤„ë°”ê¿ˆì€ \\n ì‚¬ìš©)",\n'
        '  "action_items": ["êµ¬ì²´ì ì¸ ì‹¤í–‰ ì œì•ˆ 1", "êµ¬ì²´ì ì¸ ì‹¤í–‰ ì œì•ˆ 2", ...],\n'
        '  "sources": ["ì°¸ê³ í•œ ìë£Œ ì¶œì²˜ ë˜ëŠ” ê·¼ê±° (URLì´ ìˆë‹¤ë©´ í¬í•¨)"]\n'
        "}\n\n"
        "ë§¤ì¶œ ë¶„ì„ ì§ˆë¬¸ì¸ ê²½ìš°, ë‹¨ìˆœ ìˆ˜ì¹˜ ë‚˜ì—´ë³´ë‹¤ 'ì „ëµì  ì œì•ˆ(Action Items)'ì— ì§‘ì¤‘í•˜ì„¸ìš”."
        "ì›¹ ê²€ìƒ‰ ê²°ê³¼ì¸ ê²½ìš°, ì¶œì²˜(URL)ë¥¼ `sources` í•„ë“œì— ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”."
    )
    
    # ë©”ì‹œì§€ êµ¬ì„±
    from langchain_core.messages import SystemMessage, HumanMessage
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ì§ˆë¬¸: {question}\n\n[ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°]\n{context_text}")
    ]
    
    # 3. LLM í˜¸ì¶œ
    from langchain_openai import ChatOpenAI
    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    response = await llm.ainvoke(messages)
    
    # 4. JSON íŒŒì‹± ë° ì €ì¥
    try:
        import json
        content = response.content.strip()
        
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±°
        if content.startswith("```json"):
            content = content[7:]
        elif content.startswith("```"):
             content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
        
        content = content.strip()
        
        # ìœ íš¨ì„± ê²€ì‚¬
        parsed_json = json.loads(content) 
        state["final_answer"] = json.dumps(parsed_json, ensure_ascii=False) # ë‹¤ì‹œ ë¬¸ìì—´ë¡œ ì €ì¥ (íŒŒì‹± ì„±ê³µ í™•ì¸)
        
    except Exception as e:
        print(f"JSON Parsing Error: {e}")
        # ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ í¬ë§·ì„ JSONìœ¼ë¡œ ê°•ì œ ë˜í•‘
        fallback = {
            "summary": "AI ë‹µë³€",
            "detail": response.content, # ì›ë³¸ í…ìŠ¤íŠ¸
            "action_items": [],
            "sources": []
        }
        state["final_answer"] = json.dumps(fallback, ensure_ascii=False)

    print(f"âœ… [Structured Answer] ë‹µë³€ ìƒì„± ì™„ë£Œ")
    return state


# ===== Step 7: Save Node (DB ì €ì¥) =====
async def save_node(state: InquiryState) -> InquiryState:
    """ì§ˆë¬¸ê³¼ ë‹µë³€ì„ DBì— ì €ì¥"""
    inquiry_id = save_inquiry(
        store_id=state["store_id"],
        category=state["category"],
        question=state["question"],
        answer=state["final_answer"]
    )
    
    state["inquiry_id"] = inquiry_id
    print(f"ğŸ’¾ [Save] DB ì €ì¥ ì™„ë£Œ (ID: {inquiry_id})")
    
    return state


def create_inquiry_graph():
    """
    LangGraph ìƒì„± - Hybrid Search & Fallback Logic ì ìš©
    """
    graph = StateGraph(InquiryState)
    
    # ë…¸ë“œ ë“±ë¡
    graph.add_node("router", router_node)
    graph.add_node("sales", diagnosis_node) # ì´ë¦„ì€ salesë¡œ ìœ ì§€í•˜ë˜ í•¨ìˆ˜ëŠ” diagnosisë¡œ êµì²´
    graph.add_node("manual", manual_node)
    graph.add_node("policy", policy_node)
    graph.add_node("web_search", web_search_node) # âœ¨ ì‹ ê·œ ë…¸ë“œ
    graph.add_node("answer", answer_node_v2) # V2 ì‚¬ìš©
    graph.add_node("save", save_node)
    
    # ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
    graph.set_entry_point("router")
    
    # ğŸ”¥ í•µì‹¬: Conditional Edge (ì—ì´ì „íŠ¸ê°€ ììœ¨ì ìœ¼ë¡œ ê²½ë¡œ ì„ íƒ)
    def route_question(state: InquiryState) -> str:
        """
        Router ë…¸ë“œì˜ ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œë¥¼ ê²°ì •
        
        Returns:
            "sales" | "manual" | "policy"
        """
        category = state["category"]
        print(f"ğŸ”€ [Conditional Edge] '{category}' ë…¸ë“œë¡œ ë¼ìš°íŒ…")
        return category
    
    # Router â†’ ì¡°ê±´ë¶€ ë¶„ê¸° (3ê°œ ì¤‘ 1ê°œë§Œ ì‹¤í–‰)
    graph.add_conditional_edges(
        "router",
        route_question,
        {
            "sales": "sales",
            "manual": "manual",
            "policy": "policy"
        }
    )
    
    # âœ¨ ê²€ìƒ‰ ê²°ê³¼ í‰ê°€ ë° ë¶„ê¸° ë¡œì§ (í•µì‹¬)
    def evaluate_search_result(state: InquiryState) -> str:
        """ê²€ìƒ‰ í’ˆì§ˆì„ í‰ê°€í•˜ì—¬ Web Search ì—¬ë¶€ ê²°ì •"""
        meta = state.get("search_meta", {})
        min_dist = meta.get("min_distance", 1.0)
        
        # ì„ê³„ê°’ ì„¤ì • (0.45 ì´ìƒì´ë©´ ê´€ë ¨ì„± ë‚®ìŒìœ¼ë¡œ íŒë‹¨)
        THRESHOLD = 0.45
        
        if min_dist > THRESHOLD:
            print(f"âš ï¸ [Search Check] ë¬¸ì„œ ìœ ì‚¬ë„ ë‚®ìŒ ({min_dist:.4f} > {THRESHOLD}) -> Web Search ì „í™˜")
            return "retry_web"
        else:
            return "proceed"

    # Manual/Policy -> í‰ê°€ -> (Web Search OR Answer)
    graph.add_conditional_edges(
        "manual",
        evaluate_search_result,
        {
            "proceed": "answer",
            "retry_web": "web_search"
        }
    )
    
    graph.add_conditional_edges(
        "policy",
        evaluate_search_result,
        {
            "proceed": "answer",
            "retry_web": "web_search"
        }
    )
    
    # SalesëŠ” Web Search ë¶ˆí•„ìš” (ë°ì´í„° ë¶„ì„ì´ë¯€ë¡œ)
    graph.add_edge("sales", "answer")
    
    # Web Search -> Answer
    graph.add_edge("web_search", "answer")
    
    # Answer â†’ Save â†’ END
    graph.add_edge("answer", "save")
    graph.add_edge("save", END)
    
    return graph.compile()


# ===== [Phase 1] ê²€ìƒ‰ ë° ì§„ë‹¨ ì‹¤í–‰ í•¨ìˆ˜ =====
async def run_search_check(store_id: int, question: str) -> Dict[str, Any]:
    """
    1ë‹¨ê³„: ì§ˆë¬¸ ë¶„ë¥˜ -> DB ê²€ìƒ‰ -> ìœ ì‚¬ë„ í‰ê°€ ê²°ê³¼ ë°˜í™˜
    """
    # 1. State ì´ˆê¸°í™”
    state = InquiryState(
        store_id=store_id,
        question=question,
        category="",
        sales_data={},
        manual_data=[],
        policy_data=[],
        final_answer="",
        inquiry_id=0,
        diagnosis_result=""
    )
    
    # 2. Router ì‹¤í–‰
    state = await router_node(state)
    category = state["category"]
    
    # 3. ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ ì‹¤í–‰
    top_doc = None
    min_dist = 1.0 # ê¸°ë³¸ê°’ ì´ˆê¸°í™”
    search_results = []
    
    if category == "sales":
        # ë§¤ì¶œì€ ì‚¬ìš©ìê°€ ì„ íƒí•  í•„ìš” ì—†ì´ ë¬´ì¡°ê±´ ë°ì´í„° ë¶„ì„
        state = await diagnosis_node(state)
        # ë§¤ì¶œì€ ìœ ì‚¬ë„ ê°œë…ì´ ì•„ë‹ˆë¯€ë¡œ 100% ì‹ ë¢°ë¡œ ê°„ì£¼
        min_dist = 0.0
        top_doc = {"title": "ë§¤ì¶œ ë°ì´í„° ë¶„ì„", "content": state["sales_data"]["summary_text"]}
        
    elif category == "manual":
        # ë§¤ë‰´ì–¼ ê²€ìƒ‰ ì‹¤í–‰
        state = await manual_node(state)
        docs = state.get("manual_data", [])
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (manual_nodeê°€ ë³€ê²½ëœ ìƒíƒœë¼ ê°€ì •)
        meta = state.get("search_meta", {})
        min_dist = meta.get("min_distance", 1.0)
        
        if docs:
            # ì²« ë²ˆì§¸ ë¬¸ì„œ íŒŒì‹±: "[ì œëª©] (ìœ ì‚¬ë„: 0.xx)\në‚´ìš©"
            first_line = docs[0].split("\n")[0]
            content_preview = docs[0][len(first_line)+1:]
            top_doc = {"title": first_line, "content": content_preview[:200] + "..."}
            search_results = docs # ì „ì²´ ê²°ê³¼ ì €ì¥í•´ì„œ ì „ë‹¬

    elif category == "policy":
        # ì •ì±… ê²€ìƒ‰ ì‹¤í–‰
        state = await policy_node(state)
        docs = state.get("policy_data", [])
        
        meta = state.get("search_meta", {})
        min_dist = meta.get("min_distance", 1.0)
        
        if docs:
            first_line = docs[0].split("\n")[0]
            content_preview = docs[0][len(first_line)+1:]
            top_doc = {"title": first_line, "content": content_preview[:200] + "..."}
            search_results = docs

    return {
        "category": category,
        "min_distance": min_dist,
        "similarity_score": round((1 - min_dist) * 100, 1), # 0~100 ì ìˆ˜
        "top_document": top_doc,
        "context_data": search_results if category != "sales" else [] # ë§¤ì¶œ ë°ì´í„°ëŠ” ë³„ë„ë¡œ ì²˜ë¦¬ë˜ë¯€ë¡œ contextì—ì„œ ì œì™¸í•˜ê±°ë‚˜ í¬í•¨ ê°€ëŠ¥
    }


# ===== [Phase 2] ìµœì¢… ë‹µë³€ ìƒì„± ìŠ¤íŠ¸ë¦¬ë° =====
async def run_final_answer_stream(store_id: int, question: str, category: str, mode: str, context_data: list):
    """
    2ë‹¨ê³„: ì‚¬ìš©ì ì„ íƒ(DB/Web)ì— ë”°ë¼ ë‹µë³€ ìƒì„±
    mode: 'db' (ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©) | 'web' (ì›¹ ê²€ìƒ‰ ìˆ˜í–‰)
    """
    
    # ê°€ìƒ State ë³µì›
    state = InquiryState(
        store_id=store_id, 
        question=question, 
        category=category,
        sales_data={}, manual_data=[], policy_data=[], final_answer="", inquiry_id=0, diagnosis_result=""
    )
    
    # ë§¤ì¶œì€ ì´ë¯¸ 1ë‹¨ê³„ì—ì„œ ë¶„ì„ì´ ëë‚¬ì–´ì•¼ í•˜ë‚˜, 
    # íë¦„ìƒ ì—¬ê¸°ì„œ ë‹¤ì‹œ ëŒë¦¬ê±°ë‚˜ ìºì‹œëœ ë°ì´í„°ë¥¼ ë°›ì•„ì•¼ í•¨.
    # ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•˜ê¸° ìœ„í•´ ë§¤ì¶œì€ ë‹¤ì‹œ diagnosis_nodeë¥¼ íƒœìš°ê³ ,
    # ë‚˜ë¨¸ì§€ëŠ” context_dataë¥¼ í™œìš©í•˜ê±°ë‚˜ web searchë¥¼ í•¨.
    
    yield json.dumps({"step": "init", "message": f"ğŸš€ {mode.upper()} ëª¨ë“œë¡œ ë‹µë³€ ìƒì„± ì‹œì‘..."}) + "\n"

    if category == "sales":
        # ë§¤ì¶œì€ Web Search ëŒ€ìƒì´ ì•„ë‹˜ -> ë°”ë¡œ ë¶„ì„
        yield json.dumps({"step": "sales", "message": "ğŸ“‰ ë§¤ì¶œ ë°ì´í„° ë¶„ì„ ì¤‘..."}) + "\n"
        state = await diagnosis_node(state)
        
        # ì§„ë‹¨ ê²°ê³¼ ì „ì†¡
        details = {
            "type": "analysis", 
            "summary": state["sales_data"].get("diagnosis_result"),
            "sales_summary": state["sales_data"].get("summary_text", "")[:100] + "..."
        }
        yield json.dumps({"step": "sales", "message": "âœ… ë¶„ì„ ì™„ë£Œ", "details": details}) + "\n"
        
    else:
        # manual / policy
        if mode == "web":
            # ì›¹ ê²€ìƒ‰ ë…¸ë“œ ì‹¤í–‰
            yield json.dumps({"step": "web_search", "message": "ğŸŒ ì™¸ë¶€ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘..."}) + "\n"
            state = await web_search_node(state)
            
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì „ì†¡
            web_res = state["manual_data"][0] if state["manual_data"] else ""
            details = {"type": "web_result", "content": web_res}
            yield json.dumps({"step": "web_search", "message": "âœ… ì™¸ë¶€ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ", "details": details}) + "\n"
            
        else:
            # DB ëª¨ë“œ: í´ë¼ì´ì–¸íŠ¸ê°€ ë³´ë‚¸ context_data(ê²€ìƒ‰ ê²°ê³¼)ë¥¼ stateì— ë³µì›
            # 1ë‹¨ê³„ì—ì„œ ì°¾ì€ê±¸ ê·¸ëŒ€ë¡œ ì”€
            key = "manual_data" if category == "manual" else "policy_data"
            state[key] = context_data
            
            yield json.dumps({"step": "check", "message": "ğŸ“š ë‚´ë¶€ DB ë°ì´í„° í™œìš©"}) + "\n"

    # ìµœì¢… ë‹µë³€ ìƒì„±
    yield json.dumps({"step": "answer", "message": "âœï¸ ë‹µë³€ ì‘ì„± ì¤‘..."}) + "\n"
    state = await answer_node_v2(state)
    
    # DB ì €ì¥
    yield json.dumps({"step": "save", "message": "ğŸ’¾ ê¸°ë¡ ì €ì¥ ì¤‘..."}) + "\n"
    state = await save_node(state)
    
    yield json.dumps({
        "step": "done",
        "message": "ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
        "final_answer": state["final_answer"],
        "category": state["category"]
    }) + "\n"
 