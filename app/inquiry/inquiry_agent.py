"""
í”„ëœì°¨ì´ì¦ˆ ê°€ë§¹ì  ë¬¸ì˜ ì‘ë‹µ ì—ì´ì „íŠ¸ (LangGraph)

Router ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬:
1. ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜ (ë§¤ì¶œ/ë§¤ë‰´ì–¼/ì •ì±…)
2. ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ì†ŒìŠ¤ ê²€ìƒ‰ (SQL/RAG)
3. ì¢…í•© ë‹µë³€ ìƒì„±
4. DB ì €ì¥
"""

from typing import TypedDict, List, Dict, Any, Annotated
from langgraph.graph import StateGraph, END
from app.clients.genai import genai_generate_text
from app.core.db import fetch_all
from app.inquiry.inquiry_service import save_inquiry
import json
from datetime import datetime, timedelta, date    
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# ===== ë°ì´í„° ê²€ìƒ‰ìš© íŒŒë¼ë¯¸í„° ì¶”ì¶œ í•¨ìˆ˜ (Upgrade) =====
async def extract_search_params(question: str):
    """
    ì§ˆë¬¸ ë¶„ì„ -> ë¶„ì„ ëŒ€ìƒ(ë§¤ì¥ë“¤) & í•„ìš”í•œ ë°ì´í„° ì†ŒìŠ¤(í…Œì´ë¸”) ê²°ì •
    """
    prompt = f"""
    ë‹¹ì‹ ì€ ë°ì´í„°ë² ì´ìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì•„ë˜ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
    
    ì§ˆë¬¸: "{question}"
    
    [ì¶”ì¶œ ê·œì¹™]
    
    1. target_store_codes: ë¶„ì„ ëŒ€ìƒ ë§¤ì¥ ì½”ë“œ ë¦¬ìŠ¤íŠ¸ (ë°°ì—´, 1ê°œ ì´ìƒ)
       - ë‹¨ì¼ ì§€ì  ìš”ì²­ ì‹œì—ë„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜: "ë¶€ì‚°ì " -> ["BUSAN"]
       - "ì„œìš¸", "ê°•ë‚¨" -> ["SEOUL"]
       - "ë¶€ì‚°", "ì„œë©´" -> ["BUSAN"]
       - "ê°•ì›", "ì†ì´ˆ" -> ["GANGWON"]
       - "ì„œìš¸í•˜ê³  ë¶€ì‚° ë¹„êµí•´ì¤˜" -> ["SEOUL", "BUSAN"]
       - "ì „ì²´", "ëª¨ë“ ", "ì „ ì§€ì " ë˜ëŠ” ì–¸ê¸‰ ì—†ìŒ -> ["ALL"]
       
    2. required_tables: ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì¡°íšŒí•´ì•¼ í•  í…Œì´ë¸” ë¦¬ìŠ¤íŠ¸ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)
       - "orders": ë©”ë‰´ íŒë§¤ëŸ‰, ì¸ê¸°/ë¹„ì¸ê¸° ë©”ë‰´ ì‹ë³„ (What)
       - "sales_daily": ë§¤ì¶œ ì¶”ì´, ë‚ ì”¨ ì •ë³´ í¬í•¨ (External Factor)
       - "reviews": íŒë§¤/ë§¤ì¶œì˜ 'ì›ì¸(Why)' ë¶„ì„, ê³ ê° ë°˜ì‘, ë§› í‰ê°€ (ì´ìœ /ë¶„ì„ ìš”ì²­ ì‹œ í•„ìˆ˜ í¬í•¨)
       
    [í…Œì´ë¸” ì„ íƒ ê°€ì´ë“œ]
    - "ì™œ ë§¤ì¶œì´ ì¤„ì—ˆì–´?" -> ["sales_daily", "reviews"] (ì¶”ì´ + ì›ì¸)
    - "ì•ˆ íŒ”ë¦° ë©”ë‰´ì™€ ì´ìœ " -> ["orders", "reviews"] (ë©”ë‰´ + ì›ì¸)
    - "ê·¸ëƒ¥ ë§¤ì¶œ ë³´ì—¬ì¤˜" -> ["sales_daily"]
       
    [ì¶œë ¥ ì˜ˆì‹œ]
    {{
        "target_store_codes": ["SEOUL", "BUSAN"],
        "required_tables": ["sales_daily", "reviews"],
        "reason": "ì„œìš¸ê³¼ ë¶€ì‚° ì§€ì ì˜ ë§¤ì¶œ ì¶”ì´ë¥¼ ë¹„êµí•˜ê³  ê³ ê° ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•¨"
    }}
    """
    try:
        response = await genai_generate_text(prompt)
        clean_text = response.replace("```json", "").replace("```", "").strip()
        parsed = json.loads(clean_text)
        return parsed
    except:
        return {"target_store_codes": ["ALL"], "required_tables": ["sales_daily", "orders"], "reason": "Error parsing"}


# ===== Step 1: State ì •ì˜ =====
class InquiryState(TypedDict):
    """ì—ì´ì „íŠ¸ ìƒíƒœ ê´€ë¦¬"""
    store_id: int
    question: str
    category: str  # Routerê°€ ë¶„ë¥˜í•œ ì¹´í…Œê³ ë¦¬
    
    # ê° ë…¸ë“œì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°
    sales_data: Dict[str, Any]
    manual_data: List[str]
    policy_data: List[str]
    
    # ìµœì¢… ê²°ê³¼
    final_answer: str
    inquiry_id: int
    diagnosis_result: str # ìƒˆë¡œ ì¶”ê°€ (ì§„ë‹¨ ê²°ê³¼ ìš”ì•½)


# ===== Step 2: Router Node (ì§ˆë¬¸ ë¶„ë¥˜) =====
async def router_node(state: InquiryState) -> InquiryState:
    """
    ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    - sales: ë§¤ì¶œ, ì„±ê³¼, í†µê³„ ê´€ë ¨
    - manual: ê¸°ê¸° ì‚¬ìš©ë²•, ë ˆì‹œí”¼, ê¸°ìˆ  ì§€ì›
    - policy: ìš´ì˜ ê·œì •, ê³ ê° ì‘ëŒ€, ë³¸ì‚¬ ì •ì±…
    """
    question = state["question"]
    
    prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì¹´í…Œê³ ë¦¬ë¥¼ ì •í™•íˆ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì„¸ìš”.

ì§ˆë¬¸: {question}

ì¹´í…Œê³ ë¦¬:
- sales: ë§¤ì¶œ ë°ì´í„° ë¶„ì„ì´ í•„ìš”í•œ ì§ˆë¬¸ (ë§¤ì¶œì•¡, íŒë§¤ëŸ‰, ì¸ê¸° ë©”ë‰´, ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •)
- manual: ê¸°ê¸° ì‚¬ìš©ë²•, ì²­ì†Œ ë°©ë²•, ê³ ì¥ ìˆ˜ë¦¬, ì¡°ë¦¬ë²• ë“± ë§¤ë‰´ì–¼ ê²€ìƒ‰
- policy: ìš´ì˜ ê·œì •, ê³ ê° ì‘ëŒ€, í™˜ë¶ˆ ì •ì±…, ê·¼íƒœ ê´€ë¦¬ ë“± ì •ì±… ê²€ìƒ‰ 

JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€:
{{"category": "sales|manual|policy"}}
"""
    
    result = await genai_generate_text(prompt)
    parsed = json.loads(result)
    
    state["category"] = parsed["category"]
    print(f"ğŸ” [Router] ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬: {parsed['category']}")
    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    messages = [HumanMessage(content=prompt)]
    response = await llm.ainvoke(messages)
    
    content = response.content.replace("```json", "").replace("```", "").strip()
    try:
        data = json.loads(content)
        category = data.get("category", "sales") # ê¸°ë³¸ê°’ sales
    except:
        category = "sales"
        
    print(f"ğŸ”€ [Router] Category Decision: {category} (Reason: {data.get('reason', 'N/A') if 'data' in locals() else 'Parse Error'})")
    
    # State ì—…ë°ì´íŠ¸
    state["category"] = category
    return state


# ===== Step 3: Diagnosis Node (Sales Analysis 2.0) =====
# ===== Step 3: Diagnosis Node (Multi-Store Support) =====
async def diagnosis_node(state: InquiryState) -> InquiryState:
    """
    [Sales Analysis V2] 
    1. ë§¤ì¥ Scope í™•ì¸ (ì„œìš¸/ë¶€ì‚°/ê°•ì›/ì „ì²´)
    2. ìµœê·¼ ë°ì´í„° ê¸°ì¤€ì¼(Anchor Date) ì‚°ì¶œ
    3. í•„ìš”í•œ í…Œì´ë¸”ë§Œ ê³¨ë¼ì„œ ë™ì  ì¿¼ë¦¬ (Orders / SalesDaily / Reviews)
    """
    if state["category"] != "sales":
        return state
        
    print(f"ğŸ•µï¸â€â™€ï¸ [Diagnosis V2] ë¶„ì„ ì‹œì‘: {state['question']}")
    
    # 1. ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì¶”ì¶œ (LLM)
    search_params = await extract_search_params(state['question'])
    
    target_store_codes = search_params.get("target_store_codes", ["ALL"])
    required_tables = search_params.get("required_tables", [])
    date_range_str = search_params.get("date_range", "DATE(o.ordered_at) >= DATE('now', '-7 days')")
    reason = search_params.get("reason", "")
    
    print(f"   ğŸ¯ íƒ€ê²Ÿ(List): {target_store_codes}, Tables: {required_tables}")
    
    # Store ID Mapping
    collected_data = {
        "scope": ", ".join(target_store_codes),
        "tables_used": required_tables,
        "period": "ìµœê·¼ 7ì¼ (ìë™ ì„¤ì •)" if "7 days" in date_range_str else "ì‚¬ìš©ì ì§€ì •",
        "reason": reason
    }
    
    try:
        # DB ì—°ê²° ë° ìŠ¤í† ì–´ ID ì¡°íšŒ (ê³µí†µ)
        store_codes = []
        target_ids = []
        target_store_id = None # ë‹¨ì¼ ìŠ¤í† ì–´ìš© (ë¹„ì „ìš©)

        q_stores = "SELECT store_id, store_name, region FROM stores"
        all_stores = await fetch_all(q_stores)
        
        # Scope Resolution
        if "ALL" in target_store_codes:
            store_codes = [s['store_name'] for s in all_stores]
            target_ids = [s['store_id'] for s in all_stores]
        else:
            for code in target_store_codes:
                matched = [s for s in all_stores if code in s['store_name'] or code in s['region']]
                if matched:
                    for m in matched:
                        if m['store_id'] not in target_ids:
                            target_ids.append(m['store_id'])
                            store_codes.append(m['store_name'])
        
        # [Anchor Date Fix] ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ì‹¤ì œ ë§ˆì§€ë§‰ ë‚ ì§œ í™•ì¸
        # í˜„ì¬ ì‹œìŠ¤í…œ ì‹œê°„(2026ë…„)ê³¼ ë°ì´í„° ì‹œê°„(2025ë…„) ë¶ˆì¼ì¹˜ í•´ê²°
        anchor_date = None
        q_max_date = "SELECT MAX(sale_date) as last_date FROM sales_daily"
        if target_ids:
             ids_str = ",".join(map(str, target_ids))
             q_max_date += f" WHERE store_id IN ({ids_str})"
             
        try:
            date_rows = await fetch_all(q_max_date)
            if date_rows and date_rows[0]['last_date']:
                anchor_date = date_rows[0]['last_date']
                
                # date ê°ì²´ í™•ì¸ ë° ë³€í™˜
                if isinstance(anchor_date, str):
                    curr_date = datetime.strptime(anchor_date, "%Y-%m-%d").date()
                else:
                    curr_date = anchor_date
                    
                start_date = curr_date - timedelta(days=6) # 1ì£¼ì¼
                # [CRITICAL FIX] Postgres í˜¸í™˜ì„ ìœ„í•´ ëª…ì‹œì  ë‚ ì§œ ë¬¸ìì—´ ì‚¬ìš©
                date_range_str = f"'{start_date}' AND '{curr_date}'"
                print(f"ğŸ“… [Smart Period] ë°ì´í„° ê¸°ë°˜ ê¸°ê°„ ì¬ì„¤ì •: {start_date} ~ {curr_date}")
            else:
                print("âš ï¸ [Smart Period] ë°ì´í„°ê°€ ì—†ì–´ ê¸°ë³¸ ê¸°ê°„(ìµœê·¼ 7ì¼) ì‚¬ìš©")
                # Fallback: Postgres Syntax
                date_range_str = "CURRENT_DATE - INTERVAL '7 days' AND CURRENT_DATE"
        except Exception as e:
            print(f"âš ï¸ [Smart Period] Error: {e}")
            
        print(f"ğŸ” [Diagnosis] Effective Date Range: {date_range_str}")

        # (A) Sales Daily (ë§¤ì¶œ ì¶”ì´)
        if "sales_daily" in required_tables:
            where_sql = f"DATE(s.sale_date) BETWEEN {date_range_str}"
            if target_ids:
                ids_str = ",".join(map(str, target_ids))
                where_sql += f" AND s.store_id IN ({ids_str})"
            
            q_sales = f"""
                SELECT s.sale_date, st.store_name, SUM(s.total_sales) as total_sales, SUM(s.total_orders) as total_orders, MAX(s.weather_info) as weather_info
                FROM sales_daily s
                JOIN stores st ON s.store_id = st.store_id
                WHERE {where_sql}
                GROUP BY s.sale_date, st.store_name
                ORDER BY s.sale_date ASC
            """
            rows = await fetch_all(q_sales)
            collected_data["daily_trend"] = rows
            
            # Chart Data
            chart_data = []
            for r in rows:
                chart_data.append({
                    "date": r['sale_date'],
                    "store": r['store_name'],
                    "sales": float(r['total_sales']) if r['total_sales'] else 0,
                    "orders": int(r['total_orders']) if r['total_orders'] else 0
                })
            collected_data["chart_data"] = chart_data

        # (B) Orders (ë©”ë‰´ ë¶„ì„)
        # [Safety Lock] ë©”ë‰´ ë¶„ì„(Orders) ì‹œ ë¦¬ë·° ê°•ì œ ì¶”ê°€
        if "orders" in required_tables:
            if "reviews" not in required_tables:
                print("âš ï¸ [Auto-Fix] ë©”ë‰´ ë¶„ì„ì„ ìœ„í•´ Reviews í…Œì´ë¸” ê°•ì œ ì¶”ê°€")
                required_tables.append("reviews")
                
            where_sql = f"DATE(o.ordered_at) BETWEEN {date_range_str}"
            if target_ids:
                 ids_str = ",".join(map(str, target_ids))
                 where_sql += f" AND o.store_id IN ({ids_str})"
            
            q_menu = f"""
                SELECT 
                    m.menu_id,
                    m.menu_name, 
                    m.category, 
                    SUM(o.quantity) as qty, 
                    SUM(o.total_price) as rev
                FROM orders o
                JOIN menus m ON o.menu_id = m.menu_id
                WHERE {where_sql}
                GROUP BY m.menu_id, m.menu_name, m.category
                ORDER BY qty DESC
                LIMIT 5
            """
            # 1. Top 5 Fetch
            rows_top = await fetch_all(q_menu)
            print(f"ğŸ“Š [Diagnosis] Top Menus Fetched: {len(rows_top)}")
            
            # 2. Worst 5 Fetch
            q_worst = q_menu.replace("DESC", "ASC").replace("LIMIT 5", "LIMIT 5")
            rows_worst = await fetch_all(q_worst)
            print(f"ğŸ“Š [Diagnosis] Worst Menus Fetched: {len(rows_worst)}")
            
            # 3. Review Binding Logic
            all_target_menus = rows_top + rows_worst
            target_menu_ids = [r['menu_id'] for r in all_target_menus]
            
            menu_review_map = {} 
            
            if target_menu_ids:
                 ids_str_menu = ",".join(map(str, set(target_menu_ids)))
                 q_deep = f"""
                    SELECT o.menu_id, r.rating, r.review_text, o.ordered_at
                    FROM reviews r
                    JOIN orders o ON r.order_id = o.order_id
                    WHERE o.menu_id IN ({ids_str_menu}) 
                    AND DATE(o.ordered_at) BETWEEN {date_range_str}
                    ORDER BY r.created_at DESC
                 """
                 deep_reviews = await fetch_all(q_deep)
                 print(f"ğŸ’¬ [Diagnosis] Bound Reviews Fetched: {len(deep_reviews)}")
                 
                 # UI ì¦ê±°ìš© ì €ì¥
                 collected_data["menu_specific_reviews"] = deep_reviews
                 
                 for dr in deep_reviews:
                     mid = dr['menu_id']
                     if mid not in menu_review_map:
                         menu_review_map[mid] = []
                     menu_review_map[mid].append(f"â­{dr['rating']}: {dr['review_text']}")
            
            # 4. Attach to Menu Data
            for r in rows_top:
                r['related_reviews'] = menu_review_map.get(r['menu_id'], [])[:10]
            for r in rows_worst:
                r['related_reviews'] = menu_review_map.get(r['menu_id'], [])[:10]

            collected_data["top_selling_menus"] = rows_top
            collected_data["low_selling_menus"] = rows_worst

        # (C) Reviews (ì¼ë°˜ ì¡°íšŒ)
        if "reviews" in required_tables:
            # Join with orders to get date & store filtering
            where_sql = f"DATE(o.ordered_at) BETWEEN {date_range_str}"
            if target_ids:
                ids_str = ",".join(map(str, target_ids))
                where_sql += f" AND o.store_id IN ({ids_str})"
            
            q_review = f"""
                SELECT s.store_name, r.rating, r.review_text, o.ordered_at
                FROM reviews r
                JOIN orders o ON r.order_id = o.order_id
                JOIN stores s ON o.store_id = s.store_id
                WHERE {where_sql}
                ORDER BY o.ordered_at DESC
                LIMIT 500
            """
            rows = await fetch_all(q_review)
            collected_data["recent_reviews"] = rows
            print(f"ğŸ’¬ [Diagnosis] Recent Reviews Fetched: {len(rows)}")

    except Exception as e:
        print(f"âŒ [Diagnosis] Critical Error: {e}")
        collected_data["error"] = str(e)
        collected_data["summary_text"] = f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        
    # 3. Summary Generation (LLMì„ ìœ„í•œ ìš”ì•½ í…ìŠ¤íŠ¸)
    # [Contextual Binding] ë©”ë‰´ì™€ ë¦¬ë·°ë¥¼ í•¨ê»˜ ì œê³µ
    summary_text = f"=== ğŸ“Š ë¶„ì„ ë¦¬í¬íŠ¸ ({', '.join(store_codes)}) ===\n"
    summary_text += f"ê¸°ê°„: {date_range_str}\n\n"
    
    if "daily_trend" in collected_data:
        summary_text += "[ì¼ë³„ ë§¤ì¶œ ë°ì´í„° (ì§€ì ë³„ êµ¬ë¶„)]\n"
        for r in collected_data["daily_trend"]:
            sales_val = float(r['total_sales']) if r['total_sales'] else 0
            weather = r.get('weather_info', '-')
            summary_text += f"- [{r['sale_date']}] {r['store_name']}: {sales_val:,.0f}ì› (ì£¼ë¬¸ {r['total_orders']}ê±´, ë‚ ì”¨ {weather})\n"

    if "top_selling_menus" in collected_data:
        summary_text += "\n[í†µí•© ì¸ê¸° ë©”ë‰´ Top 5 (Best)]\n"
        for m in collected_data["top_selling_menus"]:
            summary_text += f"- {m['menu_name']} ({m['category']}): {m['qty']}ê°œ íŒë§¤, {int(m['rev']):,}ì›\n"
            if 'related_reviews' in m and m['related_reviews']:
                reviews_str = " / ".join(m['related_reviews'])
                summary_text += f"  (ğŸ” ê³ ê° ë¦¬ë·°: {reviews_str})\n"

    if "low_selling_menus" in collected_data:
        summary_text += "\n[í†µí•© íŒë§¤ ì €ì¡° ë©”ë‰´ Top 5 (Worst)]\n"
        for m in collected_data["low_selling_menus"]:
            summary_text += f"- {m['menu_name']} ({m['category']}): {m['qty']}ê°œ íŒë§¤, {int(m['rev']):,}ì›\n"
            if 'related_reviews' in m and m['related_reviews']:
                reviews_str = " / ".join(m['related_reviews'])
                summary_text += f"  (ğŸ” ê³ ê° ë¦¬ë·°: {reviews_str})\n"
                
    if "recent_reviews" in collected_data and isinstance(collected_data["recent_reviews"], list):
        summary_text += "\n[ìµœê·¼ ê³ ê° ë¦¬ë·° ë°ì´í„° (ë§¤ì¥ ì „ì²´)]\n"
        for r in collected_data["recent_reviews"][:20]: # ìƒìœ„ 20ê°œë§Œ
            s_name = r.get('store_name', '')
            summary_text += f"- [{s_name}] â­{r.get('rating')}: {r.get('review_text')}\n"

    collected_data["summary_text"] = summary_text
    
    # 5. Result for Chat UI Chart (Chart Data Formatting)
    if "daily_trend" in collected_data:
        collected_data["chart_setup"] = {"title": f"ì§€ì ë³„ ë§¤ì¶œ ì¶”ì´ ë¹„êµ ({', '.join(store_codes)})"}
        total_sales = sum([float(r['total_sales']) for r in collected_data["daily_trend"] if r['total_sales']])
        total_orders = sum([int(r['total_orders']) for r in collected_data["daily_trend"] if r['total_orders']])
        
        collected_data["key_metrics"] = {
            "period": "ìµœê·¼ 7ì¼",
            "total_sales": total_sales,
            "total_orders": total_orders
        }

    # ê°„ë‹¨ ì§„ë‹¨ ì½”ë©˜íŠ¸ (íƒ€ì´í‹€ìš©)
    collected_data["diagnosis_result"] = f"ë¶„ì„ ì™„ë£Œ: {', '.join(store_codes)} (ìµœê·¼ 7ì¼)"

    state["sales_data"] = collected_data
    return state


# ===== Step 4: Manual RAG Node (ë§¤ë‰´ì–¼ ê²€ìƒ‰) =====
async def manual_node(state: InquiryState) -> InquiryState:
    """ë§¤ë‰´ì–¼ DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (Vector Search)"""
    if state["category"] != "manual":
        return state
    
    question = state["question"]
    
    # OpenAI Embeddingsë¡œ ì§ˆë¬¸ ë²¡í„°í™”
    from langchain_openai import OpenAIEmbeddings
    embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")
    question_vector = embeddings_model.embed_query(question)
    
    # pgvector ìœ ì‚¬ë„ ê²€ìƒ‰ (ì½”ì‚¬ì¸ ê±°ë¦¬ ê¸°ì¤€ Top 3)
    # distanceê°€ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬í•¨
    query = f"""
    SELECT title, content, category,
           embedding <=> '{question_vector}'::vector AS distance
    FROM manuals
    ORDER BY distance
    LIMIT 5
    """
    
    rows = await fetch_all(query)
    
    # ê²€ìƒ‰ ê²°ê³¼ ë° ìµœì†Œ ê±°ë¦¬ ì €ì¥
    min_distance = 1.0 # ê¸°ë³¸ê°’ (ë¶ˆì¼ì¹˜)
    if rows:
        min_distance = min([r['distance'] for r in rows])
        
    state["manual_data"] = [
        f"[{row['title']}] (ìœ ì‚¬ë„: {1 - row['distance']:.2f})\n{row['content']}"
        for row in rows
    ]
    # ìƒíƒœì— ê²€ìƒ‰ í’ˆì§ˆ ì ìˆ˜(ê±°ë¦¬) ì €ì¥ (ì„ì‹œ í•„ë“œ í™œìš© ë˜ëŠ” state í™•ì¥ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„  meta dict ê°™ì€ê±¸ ì“°ê±°ë‚˜ ê°„ë‹¨íˆ ì „ì—­ ë³€ìˆ˜ì²˜ëŸ¼ ì²˜ë¦¬)
    # ì—¬ê¸°ì„œëŠ” stateì— ì§ì ‘ ì €ì¥í•˜ê¸° ìœ„í•´ TypedDictë¥¼ ë¬´ì‹œí•˜ê³  ëŸ°íƒ€ì„ì— ì¶”ê°€í•˜ê±°ë‚˜, ë¯¸ë¦¬ ì •ì˜í•´ì•¼í•¨.
    # í¸ì˜ìƒ sales_data ë‚´ë¶€ì— ë©”íƒ€ë°ì´í„°ë¡œ ìˆ¨ê¸°ê±°ë‚˜, ìƒˆë¡œìš´ í•„ë“œë¥¼ ì¶”ê°€í•˜ëŠ”ê²Œ ì •ì„.
    # ê°„ë‹¨íˆ existing fieldì¸ 'diagnosis_result'ë¥¼ ë‹¤ìš©ë„ ë©”íƒ€ í•„ë“œë¡œ í™œìš©í•´ ê¼¼ìˆ˜ë¥¼ ë¶€ë¦¬ê±°ë‚˜, 
    # ì •ì„ëŒ€ë¡œ State í´ë˜ìŠ¤ ìˆ˜ì •ì´ í•„ìš”í•¨. ì—¬ê¸°ì„  State ìˆ˜ì • ì—†ì´ sales_data ë”•ì…”ë„ˆë¦¬ì— 'search_quality' í‚¤ë¥¼ ë„£ì–´ ì „ë‹¬.
    
    if "search_meta" not in state: state["search_meta"] = {}
    state["search_meta"] = {"min_distance": min_distance, "source": "manual_db"}
    
    print(f"ğŸ“– [Manual] ê²€ìƒ‰ ì™„ë£Œ (Min Distance: {min_distance:.4f})")
    return state


# ===== Step 5: Policy RAG Node (ì •ì±… ê²€ìƒ‰) =====
async def policy_node(state: InquiryState) -> InquiryState:
    """ìš´ì˜ ì •ì±… ë§¤ë‰´ì–¼ ê²€ìƒ‰ (Policies í…Œì´ë¸” ì¡°íšŒ)"""
    if state["category"] != "policy":
        return state
    
    question = state["question"]
    
    from langchain_openai import OpenAIEmbeddings
    embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")
    question_vector = embeddings_model.embed_query(question)
    
    query = f"""
    SELECT title, content, category,
           embedding <=> '{question_vector}'::vector AS distance
    FROM policies
    ORDER BY distance
    LIMIT 5
    """
    
    rows = await fetch_all(query)
    
    min_distance = 1.0
    if rows:
        min_distance = min([r['distance'] for r in rows])
        
    state["policy_data"] = [
        f"[{row['title']}] (ìœ ì‚¬ë„: {1 - row['distance']:.2f})\n{row['content']}"
        for row in rows
    ]
    
    state["search_meta"] = {"min_distance": min_distance, "source": "policy_db"}
    
    print(f"ğŸ“œ [Policy] ê²€ìƒ‰ ì™„ë£Œ (Min Distance: {min_distance:.4f})")
    return state


# ===== Step 5.5: Web Search Node (ì™¸ë¶€ ê²€ìƒ‰ - Google Grounding) =====
async def web_search_node(state: InquiryState) -> InquiryState:
    """ë‚´ë¶€ DB ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì™¸ë¶€ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ (Google Gemini Grounding)"""
    question = state["question"]
    print(f"ğŸŒ [Google Grounding] ë‚´ë¶€ ë¬¸ì„œ ë¶€ì¡± -> êµ¬ê¸€ ê²€ìƒ‰ ìˆ˜í–‰: {question}")
    
    try:
        from app.clients.genai import genai_generate_with_grounding
        
        # êµ¬ê¸€ ê²€ìƒ‰ Groundingì„ í†µí•œ ë‹µë³€ ìƒì„±
        grounded_response = await genai_generate_with_grounding(question)
        
        # ê²°ê³¼ ì €ì¥
        state["manual_data"] = [f"[Google ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ë‹µë³€]\n{grounded_response}"]
        state["search_meta"] = {"source": "web_search", "min_distance": 0.0}
        
    except Exception as e:
        print(f"âŒ Google Grounding ì‹¤íŒ¨: {e}")
        state["manual_data"] = [f"ì™¸ë¶€ ê²€ìƒ‰ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (Error: {str(e)})"]
        
    return state


# ===== Step 6: Answer Synthesis Node (ë‹µë³€ ìƒì„±) =====
async def answer_node(state: InquiryState) -> InquiryState:
    """ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±"""
    question = state["question"]
    category = state["category"]
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = ""
    if category == "sales":
        context = f"ë§¤ì¶œ ë°ì´í„°:\n{json.dumps(state.get('sales_data', {}), ensure_ascii=False, indent=2)}"
    elif category == "manual":
        context = "\n\n".join(state.get("manual_data", []))
    elif category == "policy":
        context = "\n\n".join(state.get("policy_data", []))
    
    prompt = f"""
ë‹¹ì‹ ì€ í”„ëœì°¨ì´ì¦ˆ ë³¸ì‚¬ì˜ ì¹œì ˆí•œ AI ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.
ì§ˆë¬¸ì— ëŒ€í•´ ì•„ë˜ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

**ì¤‘ìš”: ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ì„ ì—„ê²©íˆ ì§€ì¼œì„œ ë‹µë³€í•˜ì„¸ìš”.**

[Category: sales ì¼ ë•Œ]
{{
  "type": "sales",
  "summary": "ë§¤ì¶œ ì¶”ì´ì™€ íŠ¹ì´ì‚¬í•­ì— ëŒ€í•œ ì¹œì ˆí•œ ìš”ì•½ ë©˜íŠ¸ (3ë¬¸ì¥ ì´ë‚´)",
  "data": [
      {{ "date": "YYYY-MM-DD", "sales": 150000, "orders": 25 }},
      ... (ë°ì´í„° ê·¸ëŒ€ë¡œ ë³µì‚¬)
  ]
}}

[Category: manual ë˜ëŠ” policy ì¼ ë•Œ]
{{
  "type": "general",
  "title": "ê´€ë ¨ ë§¤ë‰´ì–¼/ê·œì • ì œëª©",
  "content": "í•µì‹¬ ë‚´ìš© ìš”ì•½ ë° ìƒì„¸ ì„¤ëª… (Markdown í˜•ì‹, ì¤„ë°”ê¿ˆì€ \\n ì‚¬ìš©)"
}}

ì§ˆë¬¸: {question}
ì¹´í…Œê³ ë¦¬: {category}

ì°¸ê³  ìë£Œ:
{context}
"""
    
    answer = await genai_generate_text(prompt)
    state["final_answer"] = answer
    
    print(f"âœ… [Answer] ë‹µë³€ ìƒì„± ì™„ë£Œ ({len(answer)}ì)")
    return state


# ===== Step 7: Save Node (DB ì €ì¥) =====
async def save_node(state: InquiryState) -> InquiryState:
    """ì§ˆë¬¸ê³¼ ë‹µë³€ì„ DBì— ì €ì¥"""
    inquiry_id = save_inquiry(
        store_id=state["store_id"],
        category=state["category"],
        question=state["question"],
        answer=state["final_answer"]
    )
    
    state["inquiry_id"] = inquiry_id
    print(f"ğŸ’¾ [Save] DB ì €ì¥ ì™„ë£Œ (ID: {inquiry_id})")
    
    return state


# ===== Step 6: Answer Synthesis Node (ë‹µë³€ ìƒì„± - Analytical) =====
async def answer_node_v2(state: InquiryState) -> InquiryState:
    """ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'í‘œ(Table)' ì¤‘ì‹¬ì˜ ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    question = state["question"]
    category = state["category"]
    
    # 1. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_text = ""
    if category == "sales":
        if "sales_data" in state and state["sales_data"]:
             context_text = state["sales_data"].get("summary_text", "")
    else:
        # manual / policy ë°ì´í„° í†µí•©
        docs = state.get("manual_data", []) + state.get("policy_data", [])
        context_text = "\n\n".join(docs)
    
    # 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (Markdown Table ê°•ì œ -> ìƒí™©ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ)
    system_prompt = (
        "ë‹¹ì‹ ì€ í”„ëœì°¨ì´ì¦ˆ ìˆ˜ì„ ë°ì´í„° ë¶„ì„ê°€(Chief Analyst)ì…ë‹ˆë‹¤. "
        "ì œê³µëœ [ë¶„ì„ìš© ë°ì´í„°]ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒ©íŠ¸ì— ì…ê°í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.\n\n"
        
        "[ì‘ì„± ê·œì¹™ - Strict Rules]\n"
        "1. **Reference Citation (ì¶œì²˜ ëª…ì‹œ)**: ë‹µë³€ ì‹œ ë°˜ë“œì‹œ **ì°¸ê³ í•œ ë§¤ë‰´ì–¼/ê·œì •ì˜ ì œëª©**ê³¼ í•µì‹¬ ë‚´ìš©ì„ ì¸ìš©í•´ì„œ ë‹µë³€í•˜ì„¸ìš”. ì˜ˆ: 'ì°¸ê³ í•˜ì‹  [í™˜ë¶ˆ ê·œì • ê°€ì´ë“œ]ì— ë”°ë¥´ë©´...'\n"
        "2. **Evidence Based**: [ë¶„ì„ìš© ë°ì´í„°]ì— ìˆëŠ” ë‚´ìš©ì„ ìµœìš°ì„ ìœ¼ë¡œ ê·¼ê±°ë¡œ ì‚¼ìœ¼ì„¸ìš”. ìœ ì‚¬ë„ê°€ ë†’ê²Œ ë‚˜ì˜¨ ë¬¸ì„œê°€ ìˆë‹¤ë©´ í•´ë‹¹ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ êµ¬ì„±í•˜ì„¸ìš”.\n"
        "3. **Markdown Table í•„ìˆ˜**: Best/Worst ë©”ë‰´, ì§€ì  ë¹„êµ ë“± ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë°ì´í„°ëŠ” **ë°˜ë“œì‹œ Markdown í‘œ(Table)**ë¡œ ì‘ì„±í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”. (ì»¬ëŸ¼ ì˜ˆ: ìˆœìœ„, ë©”ë‰´ëª…, íŒë§¤ëŸ‰, ë§¤ì¶œì•¡ê°€, ë¦¬ë·° ìš”ì•½)\n"
        "4. **í™”í ë‹¨ìœ„**: ë°˜ë“œì‹œ **ì›(KRW)**ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n"
        "5. **ì›ì¸ ë¶„ì„**: ì¶”ì¸¡ì´ ì•„ë‹ˆë¼ ë°ì´í„°ì— ê·¼ê±°í•œ ë¶„ì„ë§Œ ìˆ˜í–‰í•˜ì„¸ìš”."
    )
    
    # ë©”ì‹œì§€ êµ¬ì„±
    from langchain_core.messages import SystemMessage, HumanMessage
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ì§ˆë¬¸: {question}\n\n[ë¶„ì„ìš© ë°ì´í„°]\n{context_text}")
    ]
    
    # 3. LLM í˜¸ì¶œ
    from langchain_openai import ChatOpenAI
    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    response = await llm.ainvoke(messages)
    
    # 4. ê²°ê³¼ ì €ì¥ (Structured JSON ìƒì„±)
    # UIê°€ ì°¨íŠ¸, ë©”íŠ¸ë¦­, ë¦¬ë·° ê·¼ê±°ë¥¼ ë Œë”ë§í•  ìˆ˜ ìˆë„ë¡ JSON êµ¬ì¡°í™”
    final_output = {
        "answer": response.content,
        "category": category
    }
    
    if category == "sales" and "sales_data" in state:
        sd = state["sales_data"]
        final_output["chart_data"] = sd.get("chart_data")
        final_output["chart_setup"] = sd.get("chart_setup")
        final_output["key_metrics"] = sd.get("key_metrics")
        
        # [Evidence] ë¶„ì„ì— ì‚¬ìš©ëœ ë¦¬ë·° ë°ì´í„° ì „ë‹¬ (ë©”ë‰´ë³„ + ì „ì²´ ìµœì‹ )
        # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ í•©ì¹˜ê¸°
        all_reviews = sd.get("recent_reviews", []) + sd.get("menu_specific_reviews", [])
        # ê°„ë‹¨í•œ ì¤‘ë³µ ì œê±° (ë‚´ìš© ê¸°ì¤€)
        seen = set()
        unique_reviews = []
        for r in all_reviews:
            if r.get('review_text') and r['review_text'] not in seen:
                seen.add(r['review_text'])
                unique_reviews.append(r)
                
        final_output["used_reviews"] = unique_reviews
        
        # UIëŠ” 'summary' í‚¤ê°€ ì—†ìœ¼ë©´ 'answer'ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•˜ì§€ ì•ŠìŒ? 
        # detailì— ë‹µë³€ ë‚´ìš© ì €ì¥
        final_output["detail"] = response.content
    else:
        final_output["detail"] = response.content

    def json_serial(obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        raise TypeError(f"Type {type(obj)} not serializable")

    state["final_answer"] = json.dumps(final_output, ensure_ascii=False, default=json_serial)
    
    print(f"âœ… [Analyst Answer] ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ (Structured)")
    return state


# ===== Step 7: Save Node (DB ì €ì¥) =====
async def save_node(state: InquiryState) -> InquiryState:
    """ì§ˆë¬¸ê³¼ ë‹µë³€ì„ DBì— ì €ì¥"""
    inquiry_id = save_inquiry(
        store_id=state["store_id"],
        category=state["category"],
        question=state["question"],
        answer=state["final_answer"]
    )
    
    state["inquiry_id"] = inquiry_id
    print(f"ğŸ’¾ [Save] DB ì €ì¥ ì™„ë£Œ (ID: {inquiry_id})")
    
    return state


def create_inquiry_graph():
    """
    LangGraph ìƒì„± - Hybrid Search & Fallback Logic ì ìš©
    """
    graph = StateGraph(InquiryState)
    
    # ë…¸ë“œ ë“±ë¡
    graph.add_node("router", router_node)
    graph.add_node("sales", diagnosis_node) # ì´ë¦„ì€ salesë¡œ ìœ ì§€í•˜ë˜ í•¨ìˆ˜ëŠ” diagnosisë¡œ êµì²´
    graph.add_node("manual", manual_node)
    graph.add_node("policy", policy_node)
    graph.add_node("web_search", web_search_node) # âœ¨ ì‹ ê·œ ë…¸ë“œ
    graph.add_node("answer", answer_node_v2) # V2 ì‚¬ìš©
    graph.add_node("save", save_node)
    
    # ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
    graph.set_entry_point("router")
    
    # ğŸ”¥ í•µì‹¬: Conditional Edge (ì—ì´ì „íŠ¸ê°€ ììœ¨ì ìœ¼ë¡œ ê²½ë¡œ ì„ íƒ)
    def route_question(state: InquiryState) -> str:
        """
        Router ë…¸ë“œì˜ ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œë¥¼ ê²°ì •
        
        Returns:
            "sales" | "manual" | "policy"
        """
        category = state["category"]
        print(f"ğŸ”€ [Conditional Edge] '{category}' ë…¸ë“œë¡œ ë¼ìš°íŒ…")
        return category
    
    # Router â†’ ì¡°ê±´ë¶€ ë¶„ê¸° (3ê°œ ì¤‘ 1ê°œë§Œ ì‹¤í–‰)
    graph.add_conditional_edges(
        "router",
        route_question,
        {
            "sales": "sales",
            "manual": "manual",
            "policy": "policy"
        }
    )
    
    # âœ¨ ê²€ìƒ‰ ê²°ê³¼ í‰ê°€ ë° ë¶„ê¸° ë¡œì§ (í•µì‹¬)
    def evaluate_search_result(state: InquiryState) -> str:
        """ê²€ìƒ‰ í’ˆì§ˆì„ í‰ê°€í•˜ì—¬ Web Search ì—¬ë¶€ ê²°ì •"""
        meta = state.get("search_meta", {})
        min_dist = meta.get("min_distance", 1.0)
        
        # [Tuning] ì„ê³„ê°’ ì™„í™” (0.45 -> 0.65)
        # Distanceê°€ 0.65(ìœ ì‚¬ë„ 35%) ì´í•˜ì—¬ë„ ë‚´ë¶€ ë¬¸ì„œë¥¼ ë¯¿ê³  ë‹µë³€í•˜ë„ë¡ ì„¤ì •
        THRESHOLD = 0.65
        
        if min_dist > THRESHOLD:
            print(f"âš ï¸ [Search Check] ë¬¸ì„œ ìœ ì‚¬ë„ ë§¤ìš° ë‚®ìŒ ({min_dist:.4f} > {THRESHOLD}) -> Web Search ì „í™˜")
            return "retry_web"
        else:
            print(f"âœ… [Search Check] ë‚´ë¶€ ë¬¸ì„œ ì±„íƒ (Distance: {min_dist:.4f})")
            return "proceed"

    # Manual/Policy -> í‰ê°€ -> (Web Search OR Answer)
    graph.add_conditional_edges(
        "manual",
        evaluate_search_result,
        {
            "proceed": "answer",
            "retry_web": "web_search"
        }
    )
    
    graph.add_conditional_edges(
        "policy",
        evaluate_search_result,
        {
            "proceed": "answer",
            "retry_web": "web_search"
        }
    )
    
    # SalesëŠ” Web Search ë¶ˆí•„ìš” (ë°ì´í„° ë¶„ì„ì´ë¯€ë¡œ)
    graph.add_edge("sales", "answer")
    
    # Web Search -> Answer
    graph.add_edge("web_search", "answer")
    
    # Answer â†’ Save â†’ END
    graph.add_edge("answer", "save")
    graph.add_edge("save", END)
    
    return graph.compile()


# ===== [Phase 1] ê²€ìƒ‰ ë° ì§„ë‹¨ ì‹¤í–‰ í•¨ìˆ˜ =====
async def run_search_check(store_id: int, question: str) -> Dict[str, Any]:
    """
    1ë‹¨ê³„: ì§ˆë¬¸ ë¶„ë¥˜ -> DB ê²€ìƒ‰ -> ìœ ì‚¬ë„ í‰ê°€ ê²°ê³¼ ë°˜í™˜
    """
    # 1. State ì´ˆê¸°í™”
    state = InquiryState(
        store_id=store_id,
        question=question,
        category="",
        sales_data={},
        manual_data=[],
        policy_data=[],
        final_answer="",
        inquiry_id=0,
        diagnosis_result=""
    )
    
    # 2. Router ì‹¤í–‰
    state = await router_node(state)
    category = state["category"]
    
    # 3. ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ ì‹¤í–‰
    top_doc = None
    min_dist = 1.0 # ê¸°ë³¸ê°’ ì´ˆê¸°í™”
    search_results = []
    
    if category == "sales":
        # ë§¤ì¶œì€ ì‚¬ìš©ìê°€ ì„ íƒí•  í•„ìš” ì—†ì´ ë¬´ì¡°ê±´ ë°ì´í„° ë¶„ì„
        # [NEW] ì—¬ê¸°ì„œ diagnosis_nodeë¥¼ ì‹¤í–‰í•´ì„œ search_param ê²°ê³¼ê¹Œì§€ stateì— ë‹´ê¹€
        state = await diagnosis_node(state)
        # ë§¤ì¶œì€ ìœ ì‚¬ë„ ê°œë…ì´ ì•„ë‹ˆë¯€ë¡œ 100% ì‹ ë¢°ë¡œ ê°„ì£¼
        min_dist = 0.0
        # Sales Dataì—ì„œ ìš”ì•½ ì •ë³´ ì¶”ì¶œ
        sales_info = state.get("sales_data", {})
        top_doc = {
            "title": "ë§¤ì¶œ ë°ì´í„° ë¶„ì„", 
            "content": sales_info.get("summary_text", "ë¶„ì„ ê²°ê³¼ ì—†ìŒ"),
            # í”„ë¡ íŠ¸ì—”ë“œ ì „ë‹¬ìš© ë©”íƒ€ë°ì´í„° ì¶”ê°€
            "search_params": {
                "scope": sales_info.get("scope"),
                "tables_used": sales_info.get("tables_used"),
                "period": sales_info.get("period")
            }
        }
        
    elif category == "manual":
        # ë§¤ë‰´ì–¼ ê²€ìƒ‰ ì‹¤í–‰
        state = await manual_node(state)
        docs = state.get("manual_data", [])
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (manual_nodeê°€ ë³€ê²½ëœ ìƒíƒœë¼ ê°€ì •)
        meta = state.get("search_meta", {})
        min_dist = meta.get("min_distance", 1.0)
        
        if docs:
            # ì²« ë²ˆì§¸ ë¬¸ì„œ íŒŒì‹±: "[ì œëª©] (ìœ ì‚¬ë„: 0.xx)\në‚´ìš©"
            first_line = docs[0].split("\n")[0]
            content_preview = docs[0][len(first_line)+1:]
            top_doc = {"title": first_line, "content": content_preview[:200] + "..."}
            search_results = docs # ì „ì²´ ê²°ê³¼ ì €ì¥í•´ì„œ ì „ë‹¬

    elif category == "policy":
        # ì •ì±… ê²€ìƒ‰ ì‹¤í–‰
        state = await policy_node(state)
        docs = state.get("policy_data", [])
        
        meta = state.get("search_meta", {})
        min_dist = meta.get("min_distance", 1.0)
        
        if docs:
            first_line = docs[0].split("\n")[0]
            content_preview = docs[0][len(first_line)+1:]
            top_doc = {"title": first_line, "content": content_preview[:200] + "..."}
            search_results = docs

    # [Feature] AI Recommender: í›„ë³´êµ° ì¤‘ ìœ ì €ê°€ ë³¼ë§Œí•œ ë¬¸ì„œ ì¶”ì²œ
    recommendation = {"indices": [0], "comment": "ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ë¬¸ì„œì…ë‹ˆë‹¤."}
    if search_results and category != "sales":
        try:
            # í›„ë³´êµ° ì œëª©ë§Œ ì¶”ì¶œ
            titles = [c.split('\n')[0] for c in search_results]
            
            rec_prompt = f"""
            ì§ˆë¬¸: "{question}"
            
            ê²€ìƒ‰ëœ ë¬¸ì„œ ëª©ë¡:
            {json.dumps(titles, ensure_ascii=False)}
            
            ìœ„ ëª©ë¡ ì¤‘ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œë¥¼ 1ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.
            ê·¸ë¦¬ê³  ê·¸ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
            
            [ì¶œë ¥ í¬ë§·(JSON)]
            {{
                "recommended_indices": [0, 2],
                "comment": "ì§ˆë¬¸í•˜ì‹  'í™˜ë¶ˆ'ê³¼ ê´€ë ¨ëœ ê·œì •ì€ 1ë²ˆê³¼ 3ë²ˆ ë¬¸ì„œì— ì˜ ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤."
            }}
            """
            rec_res = await genai_generate_text(rec_prompt)
            rec_data = json.loads(rec_res.replace("```json", "").replace("```", "").strip())
            
            recommendation["indices"] = rec_data.get("recommended_indices", [0])
            recommendation["comment"] = rec_data.get("comment", "ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ì¶”ì²œ ë¡œì§ ì—ëŸ¬: {e}")

    return {
        "category": category,
        "min_distance": min_dist,
        "similarity_score": round((1 - min_dist) * 100, 1), # 0~100 ì ìˆ˜
        "top_document": top_doc,
        "candidates": search_results, # List of strings (formatted)
        "context_data": search_results if category != "sales" else [],
        "recommendation": recommendation, # AI ì¶”ì²œ ì •ë³´ ì¶”ê°€
        "sales_data": state.get("sales_data", {}) # [NEW] Sales Meta Data ì „ë‹¬
    }


# ===== [Phase 2] ìµœì¢… ë‹µë³€ ìƒì„± ìŠ¤íŠ¸ë¦¬ë° =====
async def run_final_answer_stream(store_id: int, question: str, category: str, mode: str, context_data: list):
    """
    2ë‹¨ê³„: ì‚¬ìš©ì ì„ íƒ(DB/Web)ì— ë”°ë¼ ë‹µë³€ ìƒì„±
    mode: 'db' (ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©) | 'web' (ì›¹ ê²€ìƒ‰ ìˆ˜í–‰)
    """
    
    # ê°€ìƒ State ë³µì›
    state = InquiryState(
        store_id=store_id, 
        question=question, 
        category=category,
        sales_data={}, manual_data=[], policy_data=[], final_answer="", inquiry_id=0, diagnosis_result=""
    )
    
    # ë§¤ì¶œì€ ì´ë¯¸ 1ë‹¨ê³„ì—ì„œ ë¶„ì„ì´ ëë‚¬ì–´ì•¼ í•˜ë‚˜, 
    # íë¦„ìƒ ì—¬ê¸°ì„œ ë‹¤ì‹œ ëŒë¦¬ê±°ë‚˜ ìºì‹œëœ ë°ì´í„°ë¥¼ ë°›ì•„ì•¼ í•¨.
    # ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•˜ê¸° ìœ„í•´ ë§¤ì¶œì€ ë‹¤ì‹œ diagnosis_nodeë¥¼ íƒœìš°ê³ ,
    # ë‚˜ë¨¸ì§€ëŠ” context_dataë¥¼ í™œìš©í•˜ê±°ë‚˜ web searchë¥¼ í•¨.
    
    yield json.dumps({"step": "init", "message": f"ğŸš€ {mode.upper()} ëª¨ë“œë¡œ ë‹µë³€ ìƒì„± ì‹œì‘..."}) + "\n"

    if category == "sales":
        # ë§¤ì¶œì€ Web Search ëŒ€ìƒì´ ì•„ë‹˜ -> ë°”ë¡œ ë¶„ì„
        yield json.dumps({"step": "sales", "message": "ğŸ“‰ ë§¤ì¶œ ë°ì´í„° ë¶„ì„ ì¤‘..."}) + "\n"
        state = await diagnosis_node(state)
        
        # ì§„ë‹¨ ê²°ê³¼ ì „ì†¡
        details = {
            "type": "analysis", 
            "summary": state["sales_data"].get("diagnosis_result"),
            "sales_summary": state["sales_data"].get("summary_text", "")[:100] + "..."
        }
        yield json.dumps({"step": "sales", "message": "âœ… ë¶„ì„ ì™„ë£Œ", "details": details}) + "\n"
        
    else:
        # manual / policy
        if mode == "web":
            # ì›¹ ê²€ìƒ‰ ë…¸ë“œ ì‹¤í–‰
            yield json.dumps({"step": "web_search", "message": "ğŸŒ ì™¸ë¶€ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘..."}) + "\n"
            state = await web_search_node(state)
            
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì „ì†¡
            web_res = state["manual_data"][0] if state["manual_data"] else ""
            details = {"type": "web_result", "content": web_res}
            yield json.dumps({"step": "web_search", "message": "âœ… ì™¸ë¶€ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ", "details": details}) + "\n"
            
        else:
            # DB ëª¨ë“œ: í´ë¼ì´ì–¸íŠ¸ê°€ ë³´ë‚¸ context_data(ê²€ìƒ‰ ê²°ê³¼)ë¥¼ stateì— ë³µì›
            # 1ë‹¨ê³„ì—ì„œ ì°¾ì€ê±¸ ê·¸ëŒ€ë¡œ ì”€
            key = "manual_data" if category == "manual" else "policy_data"
            state[key] = context_data
            
            yield json.dumps({"step": "check", "message": "ğŸ“š ë‚´ë¶€ DB ë°ì´í„° í™œìš©"}) + "\n"

    # ìµœì¢… ë‹µë³€ ìƒì„±
    yield json.dumps({"step": "answer", "message": "âœï¸ ë‹µë³€ ì‘ì„± ì¤‘..."}) + "\n"
    state = await answer_node_v2(state)
    
    # DB ì €ì¥
    yield json.dumps({"step": "save", "message": "ğŸ’¾ ê¸°ë¡ ì €ì¥ ì¤‘..."}) + "\n"
    state = await save_node(state)
    
    yield json.dumps({
        "step": "done",
        "message": "ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
        "final_answer": state["final_answer"],
        "category": state["category"]
    }) + "\n"
 