import streamlit as st
import asyncio
import time

# [ì„ì‹œ] ë°±ì—”ë“œ ì—°ë™ ì „ ê°€ì§œ ì‘ë‹µ í•¨ìˆ˜
async def get_ai_response(query_text: str):
    await asyncio.sleep(1) # ìƒê°í•˜ëŠ” ì²™ ëŒ€ê¸°
    return f"âœ… AI ë¶„ì„ ê²°ê³¼: '{query_text}'ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.\n(í˜„ì¬ UI í…ŒìŠ¤íŠ¸ ëª¨ë“œì…ë‹ˆë‹¤)"

def show_langgraph_architecture():
    """LangGraph ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
    with st.expander("ğŸ§  AI Agent ì•„í‚¤í…ì²˜ (LangGraph êµ¬ì¡°ë„)", expanded=False):
        st.markdown("""
        **ì´ AI AgentëŠ” ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ ìµœì ì˜ ê²½ë¡œë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.**
        """)
        
        # Graphvizë¡œ íë¦„ë„ ê·¸ë¦¬ê¸°
        st.graphviz_chart("""
            digraph {
                rankdir=LR;
                node [shape=box, style=filled, fillcolor="white", fontname="Malgun Gothic"];
                edge [color="#666666"];
                
                User [label="ğŸ‘¤ ì‚¬ìš©ì ì§ˆë¬¸", shape=oval, fillcolor="#FFD700", style="filled,bold"];
                Router [label="ğŸ¤– AI Router\n(ì˜ë„ íŒŒì•…/LLM)", fillcolor="#87CEEB", style="filled,rounded"];
                
                subgraph cluster_tools {
                    label = "ğŸ› ï¸ Tools & Knowledge Base";
                    style=dashed;
                    color="#444444";
                    
                    DB [label="ğŸ“Š Sales DB\n(PostgreSQL)", fillcolor="#98FB98"];
                    RAG_Manual [label="ğŸ“˜ Manual RAG\n(Vector DB)", fillcolor="#FFB6C1"];
                    RAG_Policy [label="âš–ï¸ Policy RAG\n(Vector DB)", fillcolor="#FFB6C1"];
                    Web [label="ğŸŒ Web Search\n(Tavily API)", fillcolor="#E0E0E0"];
                }
                
                End [label="ğŸ’¬ ìµœì¢… ë‹µë³€", shape=oval, fillcolor="#FFD700", style="filled,bold"];

                User -> Router [penwidth=2];
                Router -> DB [label="ë§¤ì¶œ/í†µê³„", color="green"];
                Router -> RAG_Manual [label="ë°©ë²•/ë§¤ë‰´ì–¼", color="red"];
                Router -> RAG_Policy [label="ê·œì •/ê³„ì•½", color="red"];
                Router -> Web [label="ê·¸ ì™¸ ì •ë³´", style="dashed"];
                
                DB -> End;
                RAG_Manual -> End;
                RAG_Policy -> End;
                Web -> End;
            }
        """)

def simulate_ai_reasoning(query_text):
    """AIì˜ ì‚¬ê³  ê³¼ì •ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ì‹œë®¬ë ˆì´ì…˜ í•¨ìˆ˜"""
    
    with st.status("ğŸ•µï¸â€â™‚ï¸ AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...", expanded=True) as status:
        
        # Step 1: ì˜ë„ íŒŒì•…
        st.write("ğŸ¤” ì§ˆë¬¸ ì˜ë„ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... (Router)")
        time.sleep(0.7) 
        
        tool_icon = "ğŸ¤–"
        tool_name = "General Chat"
        
        # (ì—°ì¶œ) ì§ˆë¬¸ì— ë”°ë¼ ê²½ë¡œê°€ ë°”ë€ŒëŠ” ì²™ ë³´ì—¬ì£¼ê¸°
        if any(k in query_text for k in ["ë§¤ì¶œ", "ì–¼ë§ˆ", "íŒë§¤", "ì‹¤ì ", "ìˆœìœ„", "ê°€ì¥ ë§ì´"]):
            st.write("âœ… ë¶„ë¥˜: **ë§¤ì¶œ/ë°ì´í„° ë¶„ì„ (Sales Analysis)**")
            time.sleep(0.5)
            st.write("ğŸ”Œ ë„êµ¬ ì—°ê²°: **AWS RDS (PostgreSQL)**")
            st.write("ğŸ” SQL Query ìƒì„± ë° ì‹¤í–‰ ì¤‘...")
            tool_icon = "ğŸ“Š"
            tool_name = "Sales DB Agent"
            
        elif any(k in query_text for k in ["ê·œì •", "ì •ì±…", "ê³„ì•½", "ë³µì¥", "ì‹œê°„"]):
            st.write("âœ… ë¶„ë¥˜: **ì‚¬ë‚´ ê·œì • (Company Policy)**")
            time.sleep(0.5)
            st.write("ğŸ”Œ ë„êµ¬ ì—°ê²°: **Vector DB (Embeddings)**")
            st.write("ï¿½ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ (Similarity Search)...")
            tool_icon = "âš–ï¸"
            tool_name = "Policy RAG Agent"
            
        elif any(k in query_text for k in ["ë°©ë²•", "ì–´ë–»ê²Œ", "ë§¤ë‰´ì–¼", "ë ˆì‹œí”¼", "ë§Œë“œëŠ”"]):
            st.write("âœ… ë¶„ë¥˜: **ìš´ì˜ ë§¤ë‰´ì–¼ (Operations Manual)**")
            time.sleep(0.5)
            st.write("ğŸ”Œ ë„êµ¬ ì—°ê²°: **Vector DB (Embeddings)**")
            st.write("ğŸ” ë§¤ë‰´ì–¼ ê²€ìƒ‰ ì¤‘...")
            tool_icon = "ğŸ“˜"
            tool_name = "Manual RAG Agent"
            
        elif any(k in query_text for k in ["ê²€ìƒ‰", "ì°¾ì•„ì¤˜", "ì•Œë ¤ì¤˜", "ëˆ„êµ¬"]):
            st.write("âš ï¸ ì‚¬ë‚´ ë°ì´í„° ë§¤ì¹­ ì‹¤íŒ¨")
            time.sleep(0.5)
            st.write("âœ… Fallback: **ì›¹ ê²€ìƒ‰ (Web Search)**")
            st.write("ğŸ”Œ ë„êµ¬ ì—°ê²°: **Tavily Search API**")
            tool_icon = "ğŸŒ"
            tool_name = "Web Search Agent"
        
        else:
            st.write("âœ… ë¶„ë¥˜: **ì¼ë°˜ ëŒ€í™” (General Conversation)**")
            st.write("ğŸ§  LLMì´ ì§ì ‘ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")

        time.sleep(0.5)
        
        # ìƒíƒœì°½ ì—…ë°ì´íŠ¸ (ì™„ë£Œ)
        status.update(
            label=f"ğŸš€ {tool_icon} {tool_name}ê°€ ë‹µë³€ì„ ì™„ì„±í–ˆìŠµë‹ˆë‹¤!", 
            state="complete", 
            expanded=False # ë‹¤ ëë‚˜ë©´ ì ‘ê¸°
        )

def inquiry_page():
    st.title("ğŸ¤– AI í”„ëœì°¨ì´ì¦ˆ ë§¤ë‹ˆì € (SOS)")
    st.markdown("ë§¤ì¥ ìš´ì˜ ì¤‘ ê¶ê¸ˆí•œ ì ì´ë‚˜ ê¸´ê¸‰ ìƒí™©ì„ ë¬¼ì–´ë³´ì„¸ìš”. AIê°€ ë§¤ë‰´ì–¼ê³¼ ë°ì´í„°ë¥¼ ë¶„ì„í•´ ì¦‰ì‹œ ë‹µë³€í•©ë‹ˆë‹¤.")

    # [í¬íŠ¸í´ë¦¬ì˜¤ìš©] ì•„í‚¤í…ì²˜ ë³´ì—¬ì£¼ê¸°
    show_langgraph_architecture()
    
    st.divider()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš” ì ì£¼ë‹˜! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n\n- ë§¤ì¶œ ë¶„ì„\n- ê¸°ê¸° ê³ ì¥/ê´€ë¦¬\n- ê³ ê° ì‘ëŒ€/ê·œì •"}
        ]

    # ê¸°ì¡´ ë©”ì‹œì§€ ì¶œë ¥
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° ì¶œë ¥
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ì‘ë‹µ ì²˜ë¦¬
        with st.chat_message("assistant"):
            # [í¬íŠ¸í´ë¦¬ì˜¤ìš©] AI ì‚¬ê³  ê³¼ì • ì‹œë®¬ë ˆì´ì…˜ (UI ì—°ì¶œ)
            simulate_ai_reasoning(prompt)
            
            # ì‹¤ì œ ì‘ë‹µì„ ë‹´ì„ ê³µê°„
            response_placeholder = st.empty()
            full_response = ""
            
            try:
                # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
                response = asyncio.run(get_ai_response(prompt))
                
                # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ (íƒ€ì ì¹˜ëŠ” ë“¯í•œ ì—°ì¶œ)
                for chunk in response.split():
                    full_response += chunk + " "
                    time.sleep(0.05)
                    response_placeholder.markdown(full_response + "â–Œ")
                
                response_placeholder.markdown(full_response)
                
            except Exception as e:
                error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                response_placeholder.error(error_msg)
                full_response = error_msg

            # ì‘ë‹µ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": full_response})
